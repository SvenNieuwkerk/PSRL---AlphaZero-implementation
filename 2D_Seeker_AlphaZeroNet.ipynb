{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70de07a1-3203-48de-8185-fe5ca549aecc",
   "metadata": {},
   "source": [
    "# Imports, device and seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f2261b-0766-4332-82cd-dc2b62407fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Standard libs ---\n",
    "import os, pickle\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any\n",
    "\n",
    "# --- Scientific stack ---\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- ACORL and RL ---\n",
    "from acorl.envs.seeker.seeker import SeekerEnv, SeekerEnvConfig\n",
    "\n",
    "# --- Own Code ---\n",
    "from MCTS import MCTSPlanner\n",
    "from network import SeekerAlphaZeroNet\n",
    "from utils import (\n",
    "    ReplayBufferHybrid,\n",
    "    collect_one_episode_hybrid,\n",
    "    train_step_mle,\n",
    "    train_step_mcts_distill,\n",
    "    train_step_hybrid,\n",
    "    run_eval_episodes,\n",
    "    run_debug_eval_episode,\n",
    ")\n",
    "from plot_utils import (\n",
    "#    decode_obs,\n",
    "    plot_seeker_obs,\n",
    "    plot_seeker_trajectory,\n",
    "#    collect_tree_edges,\n",
    "    plot_mcts_tree_xy,\n",
    "    plot_mcts_tree_xy_limited,\n",
    "    inspect_debug_trace_xy,\n",
    "    plot_dbg_step,\n",
    ")\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# --- Reproducibility ---\n",
    "def set_global_seeds(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "set_global_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760f965-fb94-40f9-a40a-573edb1a81cd",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40daddd1-6007-44a9-b0ee-56ae61624abc",
   "metadata": {},
   "source": [
    "## baseline config\n",
    "### Comments are explaining what each parameter does in general, but also mixed with comments that explain behavious of this specific configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44435135-4d44-463e-83a4-af8fb39898bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # ========================\n",
    "    # Environment\n",
    "    # ========================\n",
    "    max_episode_steps: int = 200  # max steps in environment before cut off (goal not reached, obstacle not crashed into --> prevent forever stepping)\n",
    "\n",
    "    # ========================\n",
    "    # MCTS core\n",
    "    # ========================\n",
    "    num_simulations: int = 400    # Number of MCTS simulations per real environment step\n",
    "    cpuct: float = 1.5            # Exploration vs exploitation tradeoff in PUCT; Higher -> more exploration guided by policy prior\n",
    "    max_depth: int = 64           # Safety cap on tree depth during a simulation\n",
    "\n",
    "    # For root action selection / Action sampling temperature at root\n",
    "    # >1.0 = more stochastic, 1.0 = proportional to visits, ~0 = greedy\n",
    "    temperature: float = 1.0\n",
    "\n",
    "    # ========================\n",
    "    # Progressive Widening\n",
    "    # ========================\n",
    "    pw_k: float = 2.0\n",
    "    # Controls how many actions are allowed per node:\n",
    "    #   K_max = pw_k * N(s)^pw_alpha\n",
    "    pw_alpha: float = 0.5\n",
    "    # Growth rate of branching factor\n",
    "    # 0.5 is common; smaller = more conservative expansion\n",
    "\n",
    "    # ========================\n",
    "    # Action sampling (baseline, non-fancy, but no duplicates)\n",
    "    # ========================\n",
    "    # --- Uniform warmstart ---\n",
    "    # No uniform warmstart, no diversity scoring\n",
    "    K_uniform_per_node: int = 8\n",
    "    # First K children per node are sampled uniformly in [-1,1]^2\n",
    "    # Set to 0 to disable\n",
    "    warmstart_iters: int = 20\n",
    "    # Number of *training iterations* during which ALL nodes use uniform sampling\n",
    "    # 0 disables global warmstart; use this if you want uniform sampling only early in training\n",
    "\n",
    "    # --- Novelty reject (hard deduplication) ---\n",
    "    # Deduplicate actions (keep this ON to satisfy “no duplicate actions”)\n",
    "    novelty_eps: float = 1e-3      # small but > 0\n",
    "    # Minimum distance between actions to be considered \"new\"\n",
    "    # In [-1,1]^2, values around 0.05–0.15 are reasonable\n",
    "    # Set <=0 to disable\n",
    "    novelty_metric: str = \"l2\"\n",
    "    # Distance metric for novelty check:\n",
    "    # \"linf\" = max(|dx|, |dy|)  (good for box action spaces)\n",
    "    # \"l2\"   = Euclidean distance\n",
    "\n",
    "    # --- Diversity scoring (soft repulsion) ---\n",
    "    # Disable candidate scoring / diversity\n",
    "    num_candidates: int = 1\n",
    "    # Number of candidate actions sampled before choosing the best\n",
    "    # <=1 disables diversity scoring\n",
    "    diversity_lambda: float = 0.0\n",
    "    # Strength of diversity penalty\n",
    "    # Higher -> stronger push away from already-sampled actions\n",
    "    # Set <=0 to disable\n",
    "    diversity_sigma: float = 0.25  # unused\n",
    "    # Length scale for diversity penalty\n",
    "    # Roughly: how far actions must be before they stop \"repelling\" each other\n",
    "    policy_beta: float = 1.0       # unused\n",
    "    # Weight of policy log-probability in candidate scoring\n",
    "    # Higher -> follow policy more closely\n",
    "    # Lower -> prioritize diversity more\n",
    "\n",
    "    # --- Resampling control ---\n",
    "    max_resample_attempts: int = 16\n",
    "    # How many times expansion may retry to find a novel action\n",
    "    # If all fail, expansion is declined and MCTS falls back to selection\n",
    "    \n",
    "    # ========================\n",
    "    # Training\n",
    "    # ========================\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    train_steps_per_iter: int = 200    # Gradient updates per outer iteration\n",
    "\n",
    "    # (Only used by our baseline loss function)\n",
    "    value_loss_weight: float = 1.0\n",
    "    policy_loss_weight: float = 1.0  # applies to mu/log_std regression\n",
    "\n",
    "    # ========================\n",
    "    # Data collection\n",
    "    # ========================\n",
    "    collect_episodes_per_iter: int = 10     # Number of real env episodes collected per training iteration\n",
    "    replay_buffer_capacity: int = 50_000\n",
    "    gamma_mcts: float = 0.975      # Discount factor for return backup in MCTS\n",
    "    gamma_mc = 0.9\n",
    "\n",
    "    # ========================\n",
    "    # Logging / evaluation\n",
    "    # ========================\n",
    "    eval_every: int = 25\n",
    "    eval_episodes: int = 50   # use 10 fixed seeds for smoother eval curves\n",
    "\n",
    "\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4deec-de0b-4760-84f6-30507402327c",
   "metadata": {},
   "source": [
    "## Sanity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbde1fad-f122-4484-b860-33233ef19456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(max_episode_steps=200,\n",
      "       num_simulations=400,\n",
      "       cpuct=1.5,\n",
      "       max_depth=64,\n",
      "       temperature=1.0,\n",
      "       pw_k=2.0,\n",
      "       pw_alpha=0.5,\n",
      "       K_uniform_per_node=8,\n",
      "       warmstart_iters=20,\n",
      "       novelty_eps=0.001,\n",
      "       novelty_metric='l2',\n",
      "       num_candidates=1,\n",
      "       diversity_lambda=0.0,\n",
      "       diversity_sigma=0.25,\n",
      "       policy_beta=1.0,\n",
      "       max_resample_attempts=16,\n",
      "       batch_size=128,\n",
      "       learning_rate=0.0003,\n",
      "       weight_decay=0.0001,\n",
      "       train_steps_per_iter=200,\n",
      "       value_loss_weight=1.0,\n",
      "       policy_loss_weight=1.0,\n",
      "       collect_episodes_per_iter=10,\n",
      "       replay_buffer_capacity=50000,\n",
      "       gamma_mcts=0.975,\n",
      "       eval_every=25,\n",
      "       eval_episodes=50)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579f70f-487f-425b-a195-3e735208649a",
   "metadata": {},
   "source": [
    "# Create env_real, env_sim, dims (for network), and step_fn (for MCTSPlanner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0951bd8a-391e-48d2-b8f7-3df7a4c14d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim: 7 action_dim: 2\n",
      "action_space: Box(-1.0, 1.0, (2,), float64)\n"
     ]
    }
   ],
   "source": [
    "# --- Env config ---\n",
    "env_config = SeekerEnvConfig(randomize=True, num_obstacles=1)\n",
    "\n",
    "# --- Real environment for rollouts / data collection ---\n",
    "env_real = SeekerEnv(**env_config.model_dump(exclude={\"id\"}))\n",
    "obs0, info0 = env_real.reset()\n",
    "\n",
    "obs_dim = env_real.observation_space.shape[0]\n",
    "action_dim = env_real.action_space.shape[0]\n",
    "\n",
    "print(\"obs_dim:\", obs_dim, \"action_dim:\", action_dim)\n",
    "print(\"action_space:\", env_real.action_space)\n",
    "\n",
    "# --- Simulation environment for MCTS step_fn ---\n",
    "env_sim = SeekerEnv(**env_config.model_dump(exclude={\"id\"}))\n",
    "\n",
    "# --- evaluation environment for evaluation during training ---\n",
    "env_eval = SeekerEnv(**env_config.model_dump(exclude={\"id\"}))\n",
    "\n",
    "\n",
    "def set_env_state_from_obs(sim_env: SeekerEnv, obs: np.ndarray):\n",
    "    \"\"\"\n",
    "    Overwrite SeekerEnv internal state to match the flat observation vector.\n",
    "\n",
    "    obs layout (from your old notebook):\n",
    "      [agent_x, agent_y, goal_x, goal_y, (obs_x, obs_y, obs_r)*N]\n",
    "    \"\"\"\n",
    "    obs = np.asarray(obs, dtype=sim_env._dtype)\n",
    "\n",
    "    # agent and goal\n",
    "    sim_env._agent_position = obs[0:2].copy()\n",
    "    sim_env._goal_position = obs[2:4].copy()\n",
    "\n",
    "    # obstacles\n",
    "    obstacles = obs[4:].reshape(-1, 3)\n",
    "    sim_env._obstacle_position = obstacles[:, 0:2].copy()\n",
    "    sim_env._obstacle_radius = obstacles[:, 2].copy()\n",
    "\n",
    "def step_fn(state: np.ndarray, action: np.ndarray):\n",
    "    \"\"\"\n",
    "    MCTS transition function: set env_sim to `state`, take `action`, return next_state/reward/done/info.\n",
    "    Returns: next_state, reward, done, info  (matching MCTSPlanner expectations)\n",
    "    \"\"\"\n",
    "    set_env_state_from_obs(env_sim, state)\n",
    "\n",
    "    action = np.asarray(action, dtype=env_sim._dtype)\n",
    "    next_obs, reward, terminated, truncated, info = env_sim.step(action)\n",
    "    done = bool(terminated or truncated)\n",
    "\n",
    "    return next_obs, float(reward), done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fc4a2-6eb2-4d5f-a6b1-69d255066219",
   "metadata": {},
   "source": [
    "# Instantiate neural network and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0822f4f-0d85-45fa-97be-080dbc5b57d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: [[-0.26337135 -0.13172348]]\n",
      "log_std: [[ 0.45294833 -0.14332369]]\n",
      "v: 0.02973608300089836\n"
     ]
    }
   ],
   "source": [
    "# --- Network ---\n",
    "net = SeekerAlphaZeroNet(obs_dim=obs_dim, action_dim=action_dim).to(device)\n",
    "\n",
    "# Optional: print one forward pass sanity\n",
    "obs_t = torch.from_numpy(obs0).float().unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    mu_t, log_std_t, v_t = net(obs_t)\n",
    "\n",
    "print(\"mu:\", mu_t.cpu().numpy())\n",
    "print(\"log_std:\", log_std_t.cpu().numpy())\n",
    "print(\"v:\", v_t.item())\n",
    "\n",
    "# --- Optimizer (we'll use later) ---\n",
    "optimizer = optim.AdamW(net.parameters(), lr=cfg.learning_rate, weight_decay=cfg.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe37236-6d23-4126-b98e-361792c51b95",
   "metadata": {},
   "source": [
    "# Instantiate MCTSPlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7047e6b0-329b-4d72-8659-6b9a61153410",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = MCTSPlanner(\n",
    "    net=net,\n",
    "    device=str(device),\n",
    "    step_fn=step_fn,\n",
    "    num_simulations=cfg.num_simulations,\n",
    "    cpuct=cfg.cpuct,\n",
    "    gamma=cfg.gamma_mcts,\n",
    "    pw_k=cfg.pw_k,\n",
    "    pw_alpha=cfg.pw_alpha,\n",
    "    max_depth=cfg.max_depth,\n",
    "    temperature=cfg.temperature,\n",
    "    rng=np.random.default_rng(SEED),\n",
    "    \n",
    "    K_uniform_per_node=cfg.K_uniform_per_node,\n",
    "    warmstart_iters=cfg.warmstart_iters,\n",
    "    novelty_eps=cfg.novelty_eps,\n",
    "    novelty_metric=cfg.novelty_metric,\n",
    "    num_candidates=cfg.num_candidates,\n",
    "    diversity_lambda=cfg.diversity_lambda,\n",
    "    diversity_sigma=cfg.diversity_sigma,\n",
    "    policy_beta=cfg.policy_beta,\n",
    "    max_resample_attempts=cfg.max_resample_attempts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa6a37-7e5b-45e2-a028-249e5c7e924c",
   "metadata": {},
   "source": [
    "# Smoke test: one MCTS search, inspect root, pick action, step env_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211c00be-3295-4df4-8ae3-fdb83c0e234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root visit count N: 400\n",
      "Root children K: 40\n",
      "[0] N_sa=   4  Q_sa=-25.7803  P_raw=1.123e-01  P=0.033  action=[ 0.5479121  -0.12224312]\n",
      "[1] N_sa=   3  Q_sa=-33.4037  P_raw=8.752e-02  P=0.026  action=[0.71719587 0.39473605]\n",
      "[2] N_sa=   2  Q_sa=-3.2607  P_raw=4.341e-02  P=0.013  action=[-0.8116453  0.9512447]\n",
      "[3] N_sa=   6  Q_sa=-17.4602  P_raw=7.721e-02  P=0.023  action=[0.5222794 0.5721286]\n",
      "[4] N_sa=  11  Q_sa=-11.2506  P_raw=5.583e-02  P=0.016  action=[-0.25840396  0.85353   ]\n",
      "Chosen action: [-0.98914033 -0.89668417]\n",
      "Step result -> reward: -1.7583429241649728 done: False\n",
      "Obs delta L2: 1.3350809324530617\n"
     ]
    }
   ],
   "source": [
    "# Reset real env\n",
    "obs, info = env_real.reset()\n",
    "\n",
    "# Run one MCTS search from the current observation\n",
    "root = planner.search(obs)\n",
    "\n",
    "print(\"Root visit count N:\", root.N)\n",
    "print(\"Root children K:\", len(root.children))\n",
    "\n",
    "# Show a few children stats\n",
    "for i, ch in enumerate(root.children[:5]):\n",
    "    print(\n",
    "        f\"[{i}] N_sa={ch.N_sa:4d}  Q_sa={ch.Q_sa:+.4f}  \"\n",
    "        f\"P_raw={ch.P_sa_raw:.3e}  P={ch.P_sa:.3f}  action={ch.action}\"\n",
    "    )\n",
    "\n",
    "# Pick an action from MCTS policy (training=True samples from visit counts)\n",
    "action = planner.act(root, training=True)\n",
    "print(\"Chosen action:\", action)\n",
    "\n",
    "# Step the real environment once\n",
    "next_obs, reward, terminated, truncated, info = env_real.step(action)\n",
    "done = bool(terminated or truncated)\n",
    "\n",
    "print(\"Step result -> reward:\", reward, \"done:\", done)\n",
    "print(\"Obs delta L2:\", np.linalg.norm(next_obs - obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004c9ca5-92c2-4bb4-a2f6-7dba78b9264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] N_sa=   4  Q_sa=-25.7803  P_raw=1.123e-01  P=0.033  action=[ 0.5479121  -0.12224312]\n",
      "[1] N_sa=   3  Q_sa=-33.4037  P_raw=8.752e-02  P=0.026  action=[0.71719587 0.39473605]\n",
      "[2] N_sa=   2  Q_sa=-3.2607  P_raw=4.341e-02  P=0.013  action=[-0.8116453  0.9512447]\n",
      "[3] N_sa=   6  Q_sa=-17.4602  P_raw=7.721e-02  P=0.023  action=[0.5222794 0.5721286]\n",
      "[4] N_sa=  11  Q_sa=-11.2506  P_raw=5.583e-02  P=0.016  action=[-0.25840396  0.85353   ]\n",
      "[5] N_sa=  30  Q_sa=-5.8916  P_raw=1.026e-01  P=0.030  action=[-0.1131716 -0.5455226]\n",
      "[6] N_sa=   2  Q_sa=-49.2811  P_raw=1.100e-01  P=0.032  action=[ 0.5161755  -0.29094806]\n",
      "[7] N_sa=  14  Q_sa=-9.0721  P_raw=7.088e-02  P=0.021  action=[-0.066558  -0.9123925]\n",
      "[8] N_sa=  13  Q_sa=-9.6279  P_raw=9.686e-02  P=0.028  action=[-0.06088838 -0.6210573 ]\n",
      "[9] N_sa=   2  Q_sa=-49.3703  P_raw=1.090e-01  P=0.032  action=[ 0.4005302  -0.37526673]\n",
      "[10] N_sa=  10  Q_sa=-11.5438  P_raw=9.534e-02  P=0.028  action=[0.5738488  0.32970172]\n",
      "[11] N_sa=   8  Q_sa=-13.7836  P_raw=8.523e-02  P=0.025  action=[0.13047221 0.5299977 ]\n",
      "[12] N_sa=   7  Q_sa=-3.1252  P_raw=9.780e-02  P=0.029  action=[-0.88339454 -0.43723223]\n",
      "[13] N_sa=  12  Q_sa=-10.2846  P_raw=1.144e-01  P=0.033  action=[ 0.4447187  -0.07624554]\n",
      "[14] N_sa=   3  Q_sa=-33.5755  P_raw=8.469e-02  P=0.025  action=[0.8171614  0.39941427]\n",
      "[15] N_sa=   9  Q_sa=-3.2206  P_raw=6.502e-02  P=0.019  action=[-0.64645445  0.7132286 ]\n",
      "[16] N_sa=  13  Q_sa=-3.1512  P_raw=5.313e-02  P=0.016  action=[-0.6588141   0.85024023]\n",
      "[17] N_sa=  37  Q_sa=-3.1399  P_raw=1.162e-01  P=0.034  action=[-0.336862    0.04134481]\n",
      "[18] N_sa=   9  Q_sa=-12.9742  P_raw=1.171e-01  P=0.034  action=[ 0.10970494 -0.25815544]\n",
      "[19] N_sa=   5  Q_sa=-20.9308  P_raw=1.133e-01  P=0.033  action=[ 0.03771672 -0.3681419 ]\n",
      "[20] N_sa=  15  Q_sa=-8.9531  P_raw=8.909e-02  P=0.026  action=[ 0.00148237 -0.712205  ]\n",
      "[21] N_sa=   5  Q_sa=-21.5932  P_raw=4.983e-02  P=0.015  action=[0.32572842 0.91124654]\n",
      "[22] N_sa=   7  Q_sa=-16.0142  P_raw=6.599e-02  P=0.019  action=[0.21203165 0.7354779 ]\n",
      "[23] N_sa=  20  Q_sa=-7.2722  P_raw=8.878e-02  P=0.026  action=[-0.43055984 -0.6927732 ]\n",
      "[24] N_sa=   1  Q_sa=-100.0000  P_raw=6.595e-02  P=0.019  action=[ 0.6669171  -0.89607626]\n",
      "[25] N_sa=   6  Q_sa=-17.9437  P_raw=1.138e-01  P=0.033  action=[-0.2672151  -0.34500888]\n",
      "[26] N_sa=  14  Q_sa=-3.1207  P_raw=4.694e-02  P=0.014  action=[-0.72518414  0.9177605 ]\n",
      "[27] N_sa=   3  Q_sa=-33.7466  P_raw=9.498e-02  P=0.028  action=[0.5486428  0.34246284]\n",
      "[28] N_sa=   7  Q_sa=-3.2523  P_raw=1.038e-01  P=0.030  action=[-0.9753946  -0.09136408]\n",
      "[29] N_sa=  30  Q_sa=-3.1257  P_raw=6.238e-02  P=0.018  action=[-0.98914033 -0.89668417]\n",
      "[30] N_sa=   3  Q_sa=-33.6083  P_raw=9.040e-02  P=0.026  action=[ 0.41915658 -0.6537443 ]\n",
      "[31] N_sa=   6  Q_sa=-17.5711  P_raw=1.125e-01  P=0.033  action=[ 0.1766125 -0.3659182]\n",
      "[32] N_sa=   8  Q_sa=-14.2174  P_raw=9.300e-02  P=0.027  action=[-0.33173993 -0.65401113]\n",
      "[33] N_sa=  10  Q_sa=-11.7616  P_raw=7.731e-02  P=0.023  action=[-0.21485457 -0.83990145]\n",
      "[34] N_sa=   6  Q_sa=-17.8780  P_raw=1.169e-01  P=0.034  action=[-0.00236608  0.06282208]\n",
      "[35] N_sa=   6  Q_sa=-17.9668  P_raw=8.929e-02  P=0.026  action=[-0.4235435  0.467507 ]\n",
      "[36] N_sa=  14  Q_sa=-9.3312  P_raw=6.159e-02  P=0.018  action=[-0.19728889  0.7912698 ]\n",
      "[37] N_sa=  18  Q_sa=-7.7518  P_raw=5.048e-02  P=0.015  action=[-0.15923646  0.9184185 ]\n",
      "[38] N_sa=   8  Q_sa=-3.2842  P_raw=6.419e-02  P=0.019  action=[-0.7939946 -0.9178418]\n",
      "[39] N_sa=  13  Q_sa=-10.1418  P_raw=7.801e-02  P=0.023  action=[-0.905252   -0.72358924]\n",
      "unique rows: 40  /  40\n"
     ]
    }
   ],
   "source": [
    "# Show all children stats\n",
    "for i, ch in enumerate(root.children):\n",
    "    print(\n",
    "        f\"[{i}] N_sa={ch.N_sa:4d}  Q_sa={ch.Q_sa:+.4f}  \"\n",
    "        f\"P_raw={ch.P_sa_raw:.3e}  P={ch.P_sa:.3f}  action={ch.action}\"\n",
    "    )\n",
    "\n",
    "actions = np.stack([ch.action for ch in root.children], axis=0)\n",
    "print(\"unique rows:\", np.unique(actions, axis=0).shape[0], \" / \", actions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998457f-3148-4876-af9c-28a734b7ebb2",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48d4d9-5b08-44a2-af70-a48db186d3a9",
   "metadata": {},
   "source": [
    "## Test randomization seed (reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129e9d34-bb96-4bb1-b3a9-d41b4d327b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of obstacles this env actually has:\n",
    "num_obstacles = (len(obs) - 4) // 3\n",
    "# also just env._num_obstacles (?)\n",
    "\n",
    "# reset real env\n",
    "obs, info = env_real.reset()\n",
    "plot_seeker_obs(obs, info, num_obstacles)\n",
    "\n",
    "# randomize=True should give different positions over next two plots, but always same due to numpy rng seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baae417e-9f8b-4706-aa5e-eeed8fb0cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.98396753 -5.17789601 -5.72715059 -5.69871882  0.58691692 -5.41791639\n",
      "  2.52576318]\n"
     ]
    }
   ],
   "source": [
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c544c6-357f-42e1-a086-84e963e988ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be:\n",
    "# [ 5.98396753 -5.17789601 -5.72715059 -5.69871882  0.58691692 -5.41791639\n",
    "#   2.52576318]\n",
    "obs == [5.98396753, -5.17789601, -5.72715059, -5.69871882, 0.58691692, -5.41791639, 2.52576318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dccbd758-e061-4bf8-a29f-ea31fcf7f77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reset real env -> different setup, but same different every time notebook is restarted ?\n",
    "obs, info = env_real.reset()\n",
    "plot_seeker_obs(obs, info, num_obstacles)\n",
    "\n",
    "# randomize=True should give different positions over next two plots, but always same due to numpy rng seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f199c1-d1ef-4698-813b-6e6679146441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.22498966 -3.75787548 -0.79074028  5.13316731 -1.03394827  0.15360326\n",
      "  2.01160903]\n"
     ]
    }
   ],
   "source": [
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4a8b5b-fae7-4ecb-8ae5-5010f7569c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be:\n",
    "# [-1.22498966 -3.75787548 -0.79074028  5.13316731 -1.03394827  0.15360326\n",
    "#   2.01160903]\n",
    "obs == [-1.22498966, -3.75787548, -0.79074028, 5.13316731, -1.03394827, 0.15360326, 2.01160903]\n",
    "# FAILS DUE TO ACTUALLY obs[0] (as an example) BEING -1.2249896644419165"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a2d1e-1166-4645-b7ed-a5d03ffad8cb",
   "metadata": {},
   "source": [
    "# create buffer, collect data, train, and log losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d10625-081b-4b0b-9cdb-653673a206a9",
   "metadata": {},
   "source": [
    "## buffer and logging containers; schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a19b9c0-71ea-4730-bafe-1ffbcc6a4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer\n",
    "replay = ReplayBufferHybrid(\n",
    "    capacity=cfg.replay_buffer_capacity,\n",
    "    obs_dim=obs_dim,\n",
    "    action_dim=action_dim,\n",
    "    K_max=32,\n",
    ")\n",
    "\n",
    "# Logging containers (easy to plot later)\n",
    "logs = {\n",
    "    \"loss_total\": [],\n",
    "    \"loss_value\": [],\n",
    "    \"loss_policy\": [],\n",
    "    \"loss_policy_distill\": [],\n",
    "    \"loss_mu\": [],\n",
    "    \"loss_log_std\": [],\n",
    "    \"ep_return\": [],\n",
    "    \"ep_length\": [],\n",
    "    \"eval_return_mean\": [],\n",
    "    \"eval_return_std\": [],\n",
    "    \"eval_length_mean\": [],\n",
    "    \"eval_length_succes\": [],\n",
    "    \"eval_length_collision\": [],\n",
    "    \"success_rate\": [],\n",
    "    \"collision_rate\": [],\n",
    "    \"max_step_rate\": [],\n",
    "    \"iter_idx_eval\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97fc4d7e-3370-48bc-8d7b-22ea058a1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## schedules (for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193277ce-b0e5-4fc9-bf89-fc3dc3f0d2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# A simple schedule for gaussian regression weight λ\\ndef lambda_gauss(iter_idx: int) -> float:\\n    # Example: off for first 10 iters, then ramp to 1.0 over 20 iters\\n    start = 10\\n    ramp = 20\\n    if iter_idx < start:\\n        return 0.0\\n    x = min(1.0, (iter_idx - start) / float(ramp))\\n    return float(x)  # ramps 0 -> 1\\n\\n\\n# Value target mixing schedule (optional)\\ndef value_mix(iter_idx: int):\\n    # Example: start with MC a bit, then prefer MCTS\\n    # You can flip this if you want.\\n    w_mcts = 1.0\\n    w_mc = 0.0\\n    return w_mcts, w_mc\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# A simple schedule for gaussian regression weight λ\n",
    "def lambda_gauss(iter_idx: int) -> float:\n",
    "    # Example: off for first 10 iters, then ramp to 1.0 over 20 iters\n",
    "    start = 10\n",
    "    ramp = 20\n",
    "    if iter_idx < start:\n",
    "        return 0.0\n",
    "    x = min(1.0, (iter_idx - start) / float(ramp))\n",
    "    return float(x)  # ramps 0 -> 1\n",
    "\n",
    "\n",
    "# Value target mixing schedule (optional)\n",
    "def value_mix(iter_idx: int):\n",
    "    # Example: start with MC a bit, then prefer MCTS\n",
    "    # You can flip this if you want.\n",
    "    w_mcts = 1.0\n",
    "    w_mc = 0.0\n",
    "    return w_mcts, w_mc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e293864-d5f1-4412-8b4b-0803446aa111",
   "metadata": {},
   "source": [
    "# Training (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b71031-8297-4f0e-99d7-0a632c89415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SEEDS = list(range(1000, 1000 + cfg.eval_episodes))  # fixed \"validation set\"\n",
    "\n",
    "EVAL_DIR = \"eval_traces_24012026\"\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b81239-bfa6-4880-bf9a-cb47ec30a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats, traces = run_eval_episodes(\n",
    "            env_eval=env_eval,\n",
    "            planner=planner,\n",
    "            seeds=EVAL_SEEDS,\n",
    "            max_steps=cfg.max_episode_steps,\n",
    "            goal_reward=env_eval._goal_reward,\n",
    "            collision_reward=env_eval._collision_reward,\n",
    "        )\n",
    "\n",
    "for seed, tr in traces.items():\n",
    "    tr[\"training_iteration\"] = 0\n",
    "\n",
    "path = os.path.join(EVAL_DIR, f\"traces_ep000000.pkl\")\n",
    "    \n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(traces, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b64688-129f-44f5-b35c-ac1321acc928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "main loop iter: 0\n",
      "time: 0.0011825999999928172\n",
      "COLLECT loop time: 50.88665259999925\n",
      "TRAIN loop time: 0.5595804000004136\n",
      "EVAL time: 153.67457019999983\n",
      "[Eval it=0] R=83.41±40.51 succ=0.98 coll=0.00 max=0.02 len_suc=21.2 len_col=0.0 \n",
      "Iter 0 | replay=448 | train_return_mean=46.89 | last_loss=0.05450979247689247\n",
      "main loop iter: 1\n",
      "time: 205.12238499999967\n",
      "COLLECT loop time: 38.78765790000034\n",
      "TRAIN loop time: 0.43955409999944095\n",
      "Iter 1 | replay=794 | train_return_mean=34.51 | last_loss=0.05355148762464523\n",
      "main loop iter: 2\n",
      "time: 244.35003629999937\n",
      "COLLECT loop time: 57.30972850000035\n",
      "TRAIN loop time: 0.5389992999998867\n",
      "Iter 2 | replay=1267 | train_return_mean=20.52 | last_loss=0.036513447761535645\n",
      "main loop iter: 3\n",
      "time: 302.1992309999996\n",
      "COLLECT loop time: 44.22463929999958\n",
      "TRAIN loop time: 0.5235350000002654\n",
      "Iter 3 | replay=1631 | train_return_mean=53.48 | last_loss=0.025353435426950455\n",
      "main loop iter: 4\n",
      "time: 346.94779990000006\n",
      "COLLECT loop time: 50.641233499999544\n",
      "TRAIN loop time: 0.5428425000000061\n",
      "Iter 4 | replay=2067 | train_return_mean=4.64 | last_loss=0.018178481608629227\n",
      "main loop iter: 5\n",
      "time: 398.13231089999954\n",
      "COLLECT loop time: 84.87615340000048\n",
      "TRAIN loop time: 0.5290510999993785\n",
      "Iter 5 | replay=2733 | train_return_mean=1.36 | last_loss=0.021745242178440094\n",
      "main loop iter: 6\n",
      "time: 483.53773809999984\n",
      "COLLECT loop time: 75.58476119999978\n",
      "TRAIN loop time: 0.5577099000001908\n",
      "Iter 6 | replay=3352 | train_return_mean=26.32 | last_loss=0.016596470028162003\n",
      "main loop iter: 7\n",
      "time: 559.6805805999993\n",
      "COLLECT loop time: 54.02715250000074\n",
      "TRAIN loop time: 0.5479470000000219\n",
      "Iter 7 | replay=3793 | train_return_mean=66.13 | last_loss=0.014987876638770103\n",
      "main loop iter: 8\n",
      "time: 614.2559824999998\n",
      "COLLECT loop time: 36.6477476\n",
      "TRAIN loop time: 0.47307329999966896\n",
      "Iter 8 | replay=4134 | train_return_mean=57.93 | last_loss=0.021702971309423447\n",
      "main loop iter: 9\n",
      "time: 651.3770898999992\n",
      "COLLECT loop time: 67.06730340000013\n",
      "TRAIN loop time: 0.4125738000002457\n",
      "Iter 9 | replay=4719 | train_return_mean=29.52 | last_loss=0.015462095849215984\n",
      "main loop iter: 10\n",
      "time: 718.8572661999997\n",
      "COLLECT loop time: 32.902157599999555\n",
      "TRAIN loop time: 0.5268452000000252\n",
      "Iter 10 | replay=4990 | train_return_mean=83.11 | last_loss=0.01021525077521801\n",
      "main loop iter: 11\n",
      "time: 752.2866563999996\n",
      "COLLECT loop time: 43.34990469999957\n",
      "TRAIN loop time: 0.5521172000007937\n",
      "Iter 11 | replay=5343 | train_return_mean=75.79 | last_loss=0.015161963179707527\n",
      "main loop iter: 12\n",
      "time: 796.1890477999996\n",
      "COLLECT loop time: 45.59525730000041\n",
      "TRAIN loop time: 0.5283879999997225\n",
      "Iter 12 | replay=5737 | train_return_mean=48.72 | last_loss=0.01134488731622696\n",
      "main loop iter: 13\n",
      "time: 842.3130692999994\n",
      "COLLECT loop time: 31.921625400000266\n",
      "TRAIN loop time: 0.5371943000000101\n",
      "Iter 13 | replay=5989 | train_return_mean=44.15 | last_loss=0.013858494348824024\n",
      "main loop iter: 14\n",
      "time: 874.7723120999999\n",
      "COLLECT loop time: 71.63564499999939\n",
      "TRAIN loop time: 0.5456038000002081\n",
      "Iter 14 | replay=6562 | train_return_mean=-20.56 | last_loss=0.012017693370580673\n",
      "main loop iter: 15\n",
      "time: 946.9540014999993\n",
      "COLLECT loop time: 28.78315290000046\n",
      "TRAIN loop time: 0.5165022999999564\n",
      "Iter 15 | replay=6822 | train_return_mean=62.92 | last_loss=0.011468476615846157\n",
      "main loop iter: 16\n",
      "time: 976.2540151999992\n",
      "COLLECT loop time: 52.854325500000414\n",
      "TRAIN loop time: 0.4523324000001594\n",
      "Iter 16 | replay=7272 | train_return_mean=55.92 | last_loss=0.011937225237488747\n",
      "main loop iter: 17\n",
      "time: 1029.5610342\n",
      "COLLECT loop time: 33.50842609999927\n",
      "TRAIN loop time: 0.4753801000006206\n",
      "Iter 17 | replay=7560 | train_return_mean=39.96 | last_loss=0.00841555930674076\n",
      "main loop iter: 18\n",
      "time: 1063.5452198999992\n",
      "COLLECT loop time: 32.03373980000015\n",
      "TRAIN loop time: 0.5136516000002302\n",
      "Iter 18 | replay=7871 | train_return_mean=80.21 | last_loss=0.009817678481340408\n",
      "main loop iter: 19\n",
      "time: 1096.0930143999994\n",
      "COLLECT loop time: 23.717388000000028\n",
      "TRAIN loop time: 0.5278014000004987\n",
      "Iter 19 | replay=8096 | train_return_mean=86.77 | last_loss=0.010398425161838531\n",
      "main loop iter: 20\n",
      "time: 1120.3385572999996\n",
      "COLLECT loop time: 30.5660084000001\n",
      "TRAIN loop time: 0.5180966999996599\n",
      "Iter 20 | replay=8346 | train_return_mean=85.98 | last_loss=0.011228825896978378\n",
      "main loop iter: 21\n",
      "time: 1151.4234382999994\n",
      "COLLECT loop time: 27.580511500000284\n",
      "TRAIN loop time: 0.5127734999996392\n",
      "Iter 21 | replay=8602 | train_return_mean=85.39 | last_loss=0.008880199864506721\n",
      "main loop iter: 22\n",
      "time: 1179.5170677999995\n",
      "COLLECT loop time: 76.29061199999978\n",
      "TRAIN loop time: 0.5157674000001862\n",
      "Iter 22 | replay=9202 | train_return_mean=10.38 | last_loss=0.009588660672307014\n",
      "main loop iter: 23\n",
      "time: 1256.3238158999993\n",
      "COLLECT loop time: 80.50687870000002\n",
      "TRAIN loop time: 0.5394341999999597\n",
      "Iter 23 | replay=9838 | train_return_mean=-34.79 | last_loss=0.013039861805737019\n",
      "main loop iter: 24\n",
      "time: 1337.3705007999997\n",
      "COLLECT loop time: 35.76770560000023\n",
      "TRAIN loop time: 0.5097900999999183\n",
      "Iter 24 | replay=10159 | train_return_mean=56.70 | last_loss=0.010898671112954617\n",
      "main loop iter: 25\n",
      "time: 1373.6483445999993\n",
      "COLLECT loop time: 32.47158919999947\n",
      "TRAIN loop time: 0.5481918000004953\n",
      "EVAL time: 321.37310120000075\n",
      "[Eval it=25] R=43.50±105.15 succ=0.84 coll=0.00 max=0.16 len_suc=21.3 len_col=0.0 \n",
      "Iter 25 | replay=10433 | train_return_mean=60.94 | last_loss=0.009795009158551693\n",
      "main loop iter: 26\n",
      "time: 1728.0417192000004\n",
      "COLLECT loop time: 62.97512729999835\n",
      "TRAIN loop time: 0.5384418000012374\n",
      "Iter 26 | replay=10963 | train_return_mean=5.44 | last_loss=0.009576442651450634\n",
      "main loop iter: 27\n",
      "time: 1791.5557491\n",
      "COLLECT loop time: 78.89403569999922\n",
      "TRAIN loop time: 0.5502591000004031\n",
      "Iter 27 | replay=11595 | train_return_mean=5.97 | last_loss=0.014849252998828888\n",
      "main loop iter: 28\n",
      "time: 1871.0004952\n",
      "COLLECT loop time: 31.236530799998945\n",
      "TRAIN loop time: 0.5462345000014466\n",
      "Iter 28 | replay=11880 | train_return_mean=84.34 | last_loss=0.014493703842163086\n",
      "main loop iter: 29\n",
      "time: 1902.7836330999999\n",
      "COLLECT loop time: 25.064786799999638\n",
      "TRAIN loop time: 0.5478229000000283\n",
      "Iter 29 | replay=12107 | train_return_mean=47.59 | last_loss=0.01637430675327778\n",
      "main loop iter: 30\n",
      "time: 1928.3965700999997\n",
      "COLLECT loop time: 55.15581100000054\n",
      "TRAIN loop time: 0.4535692999997991\n",
      "Iter 30 | replay=12543 | train_return_mean=35.86 | last_loss=0.01571008190512657\n",
      "main loop iter: 31\n",
      "time: 1984.006349199999\n",
      "COLLECT loop time: 33.57005870000103\n",
      "TRAIN loop time: 0.45027010000012524\n",
      "Iter 31 | replay=12837 | train_return_mean=82.66 | last_loss=0.02072354406118393\n",
      "main loop iter: 32\n",
      "time: 2018.0270629999995\n",
      "COLLECT loop time: 32.96932899999956\n",
      "TRAIN loop time: 0.533493200000521\n",
      "Iter 32 | replay=13136 | train_return_mean=0.65 | last_loss=0.022517941892147064\n",
      "main loop iter: 33\n",
      "time: 2051.5302142\n",
      "COLLECT loop time: 26.08661849999953\n",
      "TRAIN loop time: 0.5373459000002185\n",
      "Iter 33 | replay=13377 | train_return_mean=66.54 | last_loss=0.01094747707247734\n",
      "main loop iter: 34\n",
      "time: 2078.1545480999994\n",
      "COLLECT loop time: 26.52737089999937\n",
      "TRAIN loop time: 0.5672066000006453\n",
      "Iter 34 | replay=13566 | train_return_mean=90.16 | last_loss=0.008210827596485615\n",
      "main loop iter: 35\n",
      "time: 2105.2495302999996\n",
      "COLLECT loop time: 23.492994599999292\n",
      "TRAIN loop time: 0.5490742000001774\n",
      "Iter 35 | replay=13777 | train_return_mean=90.02 | last_loss=0.018331417813897133\n",
      "main loop iter: 36\n",
      "time: 2129.291994199999\n",
      "COLLECT loop time: 18.293651200001477\n",
      "TRAIN loop time: 0.548659599999155\n",
      "Iter 36 | replay=13954 | train_return_mean=71.15 | last_loss=0.008635228499770164\n",
      "main loop iter: 37\n",
      "time: 2148.1347355999987\n",
      "COLLECT loop time: 38.72566650000044\n",
      "TRAIN loop time: 0.5490724000010232\n",
      "Iter 37 | replay=14295 | train_return_mean=55.61 | last_loss=0.01696142926812172\n",
      "main loop iter: 38\n",
      "time: 2187.4098414\n",
      "COLLECT loop time: 45.96806519999882\n",
      "TRAIN loop time: 0.5452472000015405\n",
      "Iter 38 | replay=14696 | train_return_mean=8.15 | last_loss=0.01410054974257946\n",
      "main loop iter: 39\n",
      "time: 2233.9234782999993\n",
      "COLLECT loop time: 33.68629730000066\n",
      "TRAIN loop time: 0.5681635000000824\n",
      "Iter 39 | replay=14943 | train_return_mean=64.89 | last_loss=0.0177823044359684\n",
      "main loop iter: 40\n",
      "time: 2268.1783130000003\n",
      "COLLECT loop time: 30.498838599998635\n",
      "TRAIN loop time: 0.5370867000001454\n",
      "Iter 40 | replay=15224 | train_return_mean=82.99 | last_loss=0.013752760365605354\n",
      "main loop iter: 41\n",
      "time: 2299.2146541\n",
      "COLLECT loop time: 22.16484909999963\n",
      "TRAIN loop time: 0.5336071999990963\n",
      "Iter 41 | replay=15429 | train_return_mean=69.79 | last_loss=0.01238187961280346\n",
      "main loop iter: 42\n",
      "time: 2321.9135432000003\n",
      "COLLECT loop time: 18.702163899999505\n",
      "TRAIN loop time: 0.5667654999997467\n",
      "Iter 42 | replay=15607 | train_return_mean=91.29 | last_loss=0.012042690999805927\n",
      "main loop iter: 43\n",
      "time: 2341.1828372\n",
      "COLLECT loop time: 50.738752499999464\n",
      "TRAIN loop time: 0.445856599999388\n",
      "Iter 43 | replay=16012 | train_return_mean=19.39 | last_loss=0.01581774838268757\n",
      "main loop iter: 44\n",
      "time: 2392.367779\n",
      "COLLECT loop time: 31.652870099998836\n",
      "TRAIN loop time: 0.47290350000002945\n",
      "Iter 44 | replay=16307 | train_return_mean=59.98 | last_loss=0.010221602395176888\n",
      "main loop iter: 45\n",
      "time: 2424.493963699999\n",
      "COLLECT loop time: 26.310024300000805\n",
      "TRAIN loop time: 0.48388949999934994\n",
      "Iter 45 | replay=16551 | train_return_mean=87.42 | last_loss=0.01131499744951725\n",
      "main loop iter: 46\n",
      "time: 2451.2882277999997\n",
      "COLLECT loop time: 19.5865730000005\n",
      "TRAIN loop time: 0.4663057999987359\n",
      "Iter 46 | replay=16746 | train_return_mean=91.23 | last_loss=0.01511904876679182\n",
      "main loop iter: 47\n",
      "time: 2471.3414998999997\n",
      "COLLECT loop time: 72.51866119999977\n",
      "TRAIN loop time: 0.4554456999994727\n",
      "Iter 47 | replay=17362 | train_return_mean=-2.06 | last_loss=0.009020696394145489\n",
      "main loop iter: 48\n",
      "time: 2544.316017699999\n",
      "COLLECT loop time: 23.035677100000612\n",
      "TRAIN loop time: 0.4621004000000539\n",
      "Iter 48 | replay=17592 | train_return_mean=87.35 | last_loss=0.016396958380937576\n",
      "main loop iter: 49\n",
      "time: 2567.8140678\n",
      "COLLECT loop time: 32.427351099999214\n",
      "TRAIN loop time: 0.4558188000009977\n",
      "Iter 49 | replay=17904 | train_return_mean=78.47 | last_loss=0.016476338729262352\n",
      "main loop iter: 50\n",
      "time: 2600.6976178000004\n",
      "COLLECT loop time: 58.9625791999988\n",
      "TRAIN loop time: 0.5411834000005911\n",
      "EVAL time: 259.4990782999994\n",
      "[Eval it=50] R=62.71±79.61 succ=0.92 coll=0.00 max=0.08 len_suc=25.2 len_col=0.0 \n",
      "Iter 50 | replay=18358 | train_return_mean=33.84 | last_loss=0.00957798957824707\n",
      "main loop iter: 51\n",
      "time: 2919.7009985000004\n",
      "COLLECT loop time: 70.71648789999927\n",
      "TRAIN loop time: 0.5577221999992616\n",
      "Iter 51 | replay=18921 | train_return_mean=33.13 | last_loss=0.006683351006358862\n",
      "main loop iter: 52\n",
      "time: 2990.9756622999994\n",
      "COLLECT loop time: 81.48824410000088\n",
      "TRAIN loop time: 0.5367404999997234\n",
      "Iter 52 | replay=19548 | train_return_mean=8.05 | last_loss=0.013155924156308174\n",
      "main loop iter: 53\n",
      "time: 3073.0010017000004\n",
      "COLLECT loop time: 75.9673727999998\n",
      "TRAIN loop time: 0.5540196999991167\n",
      "Iter 53 | replay=20136 | train_return_mean=11.86 | last_loss=0.010567234829068184\n",
      "main loop iter: 54\n",
      "time: 3149.5227744999993\n",
      "COLLECT loop time: 41.13192220000019\n",
      "TRAIN loop time: 0.4954314999995404\n",
      "Iter 54 | replay=20512 | train_return_mean=40.91 | last_loss=0.016191788017749786\n",
      "main loop iter: 55\n",
      "time: 3191.150434699999\n",
      "COLLECT loop time: 29.679771200000687\n",
      "TRAIN loop time: 0.4536041999999725\n",
      "Iter 55 | replay=20804 | train_return_mean=79.81 | last_loss=0.010168468579649925\n",
      "main loop iter: 56\n",
      "time: 3221.2840969999997\n",
      "COLLECT loop time: 31.131468100000347\n",
      "TRAIN loop time: 0.4769622999992862\n",
      "Iter 56 | replay=21054 | train_return_mean=65.83 | last_loss=0.01457207277417183\n",
      "main loop iter: 57\n",
      "time: 3252.8929054\n",
      "COLLECT loop time: 19.348327399999107\n",
      "TRAIN loop time: 0.45631850000063423\n",
      "Iter 57 | replay=21241 | train_return_mean=91.76 | last_loss=0.018406759947538376\n",
      "main loop iter: 58\n",
      "time: 3272.6978934\n",
      "COLLECT loop time: 58.462259099998846\n",
      "TRAIN loop time: 0.45423830000072485\n",
      "Iter 58 | replay=21730 | train_return_mean=30.73 | last_loss=0.013637240044772625\n",
      "main loop iter: 59\n",
      "time: 3331.6147156999996\n",
      "COLLECT loop time: 28.72000250000019\n",
      "TRAIN loop time: 0.39786760000060895\n",
      "Iter 59 | replay=22016 | train_return_mean=40.16 | last_loss=0.018561771139502525\n",
      "main loop iter: 60\n",
      "time: 3360.7329069999996\n",
      "COLLECT loop time: 16.78864590000012\n",
      "TRAIN loop time: 0.470382100000279\n",
      "Iter 60 | replay=22195 | train_return_mean=92.34 | last_loss=0.011778660118579865\n",
      "main loop iter: 61\n",
      "time: 3377.9922933999987\n",
      "COLLECT loop time: 76.73879370000031\n",
      "TRAIN loop time: 0.4588285000008909\n",
      "Iter 61 | replay=22823 | train_return_mean=6.69 | last_loss=0.014264501631259918\n",
      "main loop iter: 62\n",
      "time: 3455.1902150999995\n",
      "COLLECT loop time: 62.29735529999925\n",
      "TRAIN loop time: 0.46735050000097544\n",
      "Iter 62 | replay=23387 | train_return_mean=44.25 | last_loss=0.011897130869328976\n",
      "main loop iter: 63\n",
      "time: 3517.9553582999997\n",
      "COLLECT loop time: 64.32547779999913\n",
      "TRAIN loop time: 0.4504895000009128\n",
      "Iter 63 | replay=23915 | train_return_mean=16.73 | last_loss=0.015371737070381641\n",
      "main loop iter: 64\n",
      "time: 3582.7316536\n",
      "COLLECT loop time: 62.158127599999716\n",
      "TRAIN loop time: 0.47436170000037237\n",
      "Iter 64 | replay=24442 | train_return_mean=36.26 | last_loss=0.01858483999967575\n",
      "main loop iter: 65\n",
      "time: 3645.3644955\n",
      "COLLECT loop time: 47.10364490000029\n",
      "TRAIN loop time: 0.46577549999892653\n",
      "Iter 65 | replay=24865 | train_return_mean=59.56 | last_loss=0.0127435103058815\n",
      "main loop iter: 66\n",
      "time: 3692.9342939999988\n",
      "COLLECT loop time: 67.79301510000005\n",
      "TRAIN loop time: 0.4582858000012493\n",
      "Iter 66 | replay=25436 | train_return_mean=33.88 | last_loss=0.018974309787154198\n",
      "main loop iter: 67\n",
      "time: 3761.1859667999997\n",
      "COLLECT loop time: 19.898222899999382\n",
      "TRAIN loop time: 0.4586414000004879\n",
      "Iter 67 | replay=25628 | train_return_mean=90.83 | last_loss=0.012847507372498512\n",
      "main loop iter: 68\n",
      "time: 3781.543248099999\n",
      "COLLECT loop time: 194.57393740000043\n",
      "TRAIN loop time: 0.5540259999997943\n",
      "Iter 68 | replay=26772 | train_return_mean=-76.81 | last_loss=0.012608468532562256\n",
      "main loop iter: 69\n",
      "time: 3976.671637399999\n",
      "COLLECT loop time: 39.56494680000105\n",
      "TRAIN loop time: 0.5626274999995076\n",
      "Iter 69 | replay=27120 | train_return_mean=75.92 | last_loss=0.015628132969141006\n",
      "main loop iter: 70\n",
      "time: 4016.7995665\n",
      "COLLECT loop time: 42.697668599999815\n",
      "TRAIN loop time: 0.5435486000005767\n",
      "Iter 70 | replay=27490 | train_return_mean=29.82 | last_loss=0.015201039612293243\n",
      "main loop iter: 71\n",
      "time: 4060.0411619999995\n",
      "COLLECT loop time: 101.79833449999933\n",
      "TRAIN loop time: 0.5491061000011541\n",
      "Iter 71 | replay=28287 | train_return_mean=-20.33 | last_loss=0.014100857079029083\n",
      "main loop iter: 72\n",
      "time: 4162.3889712\n",
      "COLLECT loop time: 56.46000730000014\n",
      "TRAIN loop time: 0.5590039999988221\n",
      "Iter 72 | replay=28731 | train_return_mean=55.24 | last_loss=0.0069152843207120895\n",
      "main loop iter: 73\n",
      "time: 4219.4084053999995\n",
      "COLLECT loop time: 74.36316249999982\n",
      "TRAIN loop time: 0.455280700000003\n",
      "Iter 73 | replay=29348 | train_return_mean=6.54 | last_loss=0.021274525672197342\n",
      "main loop iter: 74\n",
      "time: 4294.2272116\n",
      "COLLECT loop time: 24.077241199998753\n",
      "TRAIN loop time: 0.44874049999998533\n",
      "Iter 74 | replay=29575 | train_return_mean=87.96 | last_loss=0.01303151436150074\n",
      "main loop iter: 75\n",
      "time: 4318.7535632\n",
      "COLLECT loop time: 48.00109580000026\n",
      "TRAIN loop time: 0.39837809999880847\n",
      "EVAL time: 308.4799278999999\n",
      "[Eval it=75] R=44.90±104.82 succ=0.84 coll=0.00 max=0.16 len_suc=19.9 len_col=0.0 \n",
      "Iter 75 | replay=29987 | train_return_mean=68.74 | last_loss=0.010171881876885891\n",
      "main loop iter: 76\n",
      "time: 4675.6337932999995\n",
      "COLLECT loop time: 126.91910680000001\n",
      "TRAIN loop time: 0.5643739000006462\n",
      "Iter 76 | replay=30543 | train_return_mean=-9.04 | last_loss=0.01953820139169693\n",
      "main loop iter: 77\n",
      "time: 4803.1177183\n",
      "COLLECT loop time: 111.39059689999885\n",
      "TRAIN loop time: 0.5572325000011915\n",
      "Iter 77 | replay=31413 | train_return_mean=-20.86 | last_loss=0.014854056760668755\n",
      "main loop iter: 78\n",
      "time: 4915.0659426\n",
      "COLLECT loop time: 65.846340099999\n",
      "TRAIN loop time: 0.4601652000001195\n",
      "Iter 78 | replay=31970 | train_return_mean=32.86 | last_loss=0.009599621407687664\n",
      "main loop iter: 79\n",
      "time: 4981.3727205\n",
      "COLLECT loop time: 31.12352909999936\n",
      "TRAIN loop time: 0.5048070000011649\n",
      "Iter 79 | replay=32206 | train_return_mean=66.51 | last_loss=0.012295800261199474\n",
      "main loop iter: 80\n",
      "time: 5013.0014006\n",
      "COLLECT loop time: 66.34322359999896\n",
      "TRAIN loop time: 0.46428970000124536\n",
      "Iter 80 | replay=32794 | train_return_mean=43.36 | last_loss=0.012419668957591057\n",
      "main loop iter: 81\n",
      "time: 5079.8092787000005\n",
      "COLLECT loop time: 119.97480759999962\n",
      "TRAIN loop time: 0.49395499999991443\n",
      "Iter 81 | replay=33659 | train_return_mean=-7.77 | last_loss=0.014952129684388638\n",
      "main loop iter: 82\n",
      "time: 5200.278422899999\n",
      "COLLECT loop time: 23.739798900000096\n",
      "TRAIN loop time: 0.5067233000008855\n",
      "Iter 82 | replay=33884 | train_return_mean=88.24 | last_loss=0.013877712190151215\n",
      "main loop iter: 83\n",
      "time: 5224.5253011\n",
      "COLLECT loop time: 45.79594829999951\n",
      "TRAIN loop time: 0.45917519999966316\n",
      "Iter 83 | replay=34248 | train_return_mean=61.36 | last_loss=0.014897963032126427\n",
      "main loop iter: 84\n",
      "time: 5270.780757799999\n",
      "COLLECT loop time: 64.65299589999995\n",
      "TRAIN loop time: 0.5224209000007249\n",
      "Iter 84 | replay=34825 | train_return_mean=29.48 | last_loss=0.0224173404276371\n",
      "main loop iter: 85\n",
      "time: 5335.9565946\n",
      "COLLECT loop time: 51.39346349999869\n",
      "TRAIN loop time: 0.4067681000015\n",
      "Iter 85 | replay=35233 | train_return_mean=36.10 | last_loss=0.02309015579521656\n",
      "main loop iter: 86\n",
      "time: 5387.7569888\n",
      "COLLECT loop time: 71.27403779999986\n",
      "TRAIN loop time: 0.5586060000005091\n",
      "Iter 86 | replay=35818 | train_return_mean=30.33 | last_loss=0.02421722188591957\n",
      "main loop iter: 87\n",
      "time: 5459.5901123\n",
      "COLLECT loop time: 83.25141499999881\n",
      "TRAIN loop time: 0.4951643000003969\n",
      "Iter 87 | replay=36417 | train_return_mean=29.72 | last_loss=0.01835336536169052\n",
      "main loop iter: 88\n",
      "time: 5543.337157799999\n",
      "COLLECT loop time: 44.49424800000088\n",
      "TRAIN loop time: 0.5713393000005453\n",
      "Iter 88 | replay=36814 | train_return_mean=37.46 | last_loss=0.02052256464958191\n",
      "main loop iter: 89\n",
      "time: 5588.403190499999\n",
      "COLLECT loop time: 53.75277070000084\n",
      "TRAIN loop time: 0.5678674999999203\n",
      "Iter 89 | replay=37211 | train_return_mean=58.41 | last_loss=0.011612864211201668\n",
      "main loop iter: 90\n",
      "time: 5642.7242627\n",
      "COLLECT loop time: 40.1056652999996\n",
      "TRAIN loop time: 0.571459099999629\n",
      "Iter 90 | replay=37552 | train_return_mean=77.03 | last_loss=0.016280950978398323\n",
      "main loop iter: 91\n",
      "time: 5683.4018909999995\n",
      "COLLECT loop time: 28.718330100000458\n",
      "TRAIN loop time: 0.5674012999988918\n",
      "Iter 91 | replay=37816 | train_return_mean=83.26 | last_loss=0.014861004427075386\n",
      "main loop iter: 92\n",
      "time: 5712.6880052\n",
      "COLLECT loop time: 103.17473210000026\n",
      "TRAIN loop time: 0.5384302999991633\n",
      "Iter 92 | replay=38608 | train_return_mean=-1.31 | last_loss=0.014476456679403782\n",
      "main loop iter: 93\n",
      "time: 5816.4016188000005\n",
      "COLLECT loop time: 62.347021999999924\n",
      "TRAIN loop time: 0.5616413999996439\n",
      "Iter 93 | replay=39121 | train_return_mean=49.32 | last_loss=0.020672421902418137\n",
      "main loop iter: 94\n",
      "time: 5879.3107203\n",
      "COLLECT loop time: 51.064709199999925\n",
      "TRAIN loop time: 0.5621714999997494\n",
      "Iter 94 | replay=39495 | train_return_mean=52.68 | last_loss=0.014905184507369995\n",
      "main loop iter: 95\n",
      "time: 5930.937925\n",
      "COLLECT loop time: 23.97637979999854\n",
      "TRAIN loop time: 0.5700468000013643\n",
      "Iter 95 | replay=39714 | train_return_mean=46.58 | last_loss=0.008082747459411621\n",
      "main loop iter: 96\n",
      "time: 5955.484550899999\n",
      "COLLECT loop time: 108.68643110000085\n",
      "TRAIN loop time: 0.47368490000008023\n",
      "Iter 96 | replay=40596 | train_return_mean=-11.74 | last_loss=0.021008513867855072\n",
      "main loop iter: 97\n",
      "time: 6064.6450167\n",
      "COLLECT loop time: 90.83424949999971\n",
      "TRAIN loop time: 0.4957947000002605\n",
      "Iter 97 | replay=41329 | train_return_mean=-35.33 | last_loss=0.020850233733654022\n",
      "main loop iter: 98\n",
      "time: 6155.9754410000005\n",
      "COLLECT loop time: 62.30634939999982\n",
      "TRAIN loop time: 0.4587999999985186\n",
      "Iter 98 | replay=41874 | train_return_mean=45.08 | last_loss=0.024906029924750328\n",
      "main loop iter: 99\n",
      "time: 6218.7409243\n",
      "COLLECT loop time: 42.993880799998806\n",
      "TRAIN loop time: 0.5525525000011839\n",
      "Iter 99 | replay=42263 | train_return_mean=61.67 | last_loss=0.036010485142469406\n",
      "main loop iter: 100\n",
      "time: 6262.287669199999\n",
      "COLLECT loop time: 51.12014790000103\n",
      "TRAIN loop time: 0.5574239999987185\n",
      "EVAL time: 734.7340912\n",
      "[Eval it=100] R=-46.00±140.49 succ=0.54 coll=0.00 max=0.46 len_suc=28.1 len_col=0.0 \n",
      "Iter 100 | replay=42631 | train_return_mean=75.23 | last_loss=0.041411422193050385\n",
      "main loop iter: 101\n",
      "time: 7048.700255399999\n",
      "COLLECT loop time: 27.47088740000072\n",
      "TRAIN loop time: 0.5757806999990862\n",
      "Iter 101 | replay=42865 | train_return_mean=44.92 | last_loss=0.019365869462490082\n",
      "main loop iter: 102\n",
      "time: 7076.7473617\n",
      "COLLECT loop time: 37.419836099999884\n",
      "TRAIN loop time: 0.5761254999997618\n",
      "Iter 102 | replay=43184 | train_return_mean=37.33 | last_loss=0.01972837746143341\n",
      "main loop iter: 103\n",
      "time: 7114.7436892000005\n",
      "COLLECT loop time: 86.61150669999915\n",
      "TRAIN loop time: 0.5591182999996818\n",
      "Iter 103 | replay=43802 | train_return_mean=-15.11 | last_loss=0.01750238426029682\n",
      "main loop iter: 104\n",
      "time: 7201.9146686\n",
      "COLLECT loop time: 56.75730549999935\n",
      "TRAIN loop time: 0.6177602000007028\n",
      "Iter 104 | replay=44266 | train_return_mean=21.49 | last_loss=0.017588788643479347\n",
      "main loop iter: 105\n",
      "time: 7259.2900797\n",
      "COLLECT loop time: 71.89577889999964\n",
      "TRAIN loop time: 0.5877280999993673\n",
      "Iter 105 | replay=44858 | train_return_mean=28.51 | last_loss=0.0646279901266098\n",
      "main loop iter: 106\n",
      "time: 7331.7740099\n",
      "COLLECT loop time: 108.6370238999989\n",
      "TRAIN loop time: 0.485271700001249\n",
      "Iter 106 | replay=45643 | train_return_mean=1.99 | last_loss=0.023645376786589622\n",
      "main loop iter: 107\n",
      "time: 7440.8967058\n",
      "COLLECT loop time: 102.90662490000068\n",
      "TRAIN loop time: 0.5409041999992041\n",
      "Iter 107 | replay=46539 | train_return_mean=-43.86 | last_loss=0.03151441365480423\n",
      "main loop iter: 108\n",
      "time: 7544.344606799999\n",
      "COLLECT loop time: 19.974344899999778\n",
      "TRAIN loop time: 0.56950660000075\n",
      "Iter 108 | replay=46726 | train_return_mean=90.16 | last_loss=0.032995693385601044\n",
      "main loop iter: 109\n",
      "time: 7564.888784999999\n",
      "COLLECT loop time: 96.81465659999958\n",
      "TRAIN loop time: 0.5761677000009513\n",
      "Iter 109 | replay=47519 | train_return_mean=-21.70 | last_loss=0.028223298490047455\n",
      "main loop iter: 110\n",
      "time: 7662.280049499999\n",
      "COLLECT loop time: 118.44754790000115\n",
      "TRAIN loop time: 0.5944545999991533\n",
      "Iter 110 | replay=48350 | train_return_mean=-29.70 | last_loss=0.02254066988825798\n",
      "main loop iter: 111\n",
      "time: 7781.322584899999\n",
      "COLLECT loop time: 122.19480889999977\n",
      "TRAIN loop time: 0.4981690000004164\n",
      "Iter 111 | replay=49359 | train_return_mean=-95.57 | last_loss=0.0363164022564888\n",
      "main loop iter: 112\n",
      "time: 7904.016077299999\n",
      "COLLECT loop time: 68.36844900000142\n",
      "TRAIN loop time: 0.5161346999993839\n",
      "Iter 112 | replay=49942 | train_return_mean=-11.02 | last_loss=0.023973535746335983\n",
      "main loop iter: 113\n",
      "time: 7972.900993899999\n",
      "COLLECT loop time: 128.40628460000153\n",
      "TRAIN loop time: 0.5684641999996529\n",
      "Iter 113 | replay=50000 | train_return_mean=-49.83 | last_loss=0.036532290279865265\n",
      "main loop iter: 114\n",
      "time: 8101.876082299999\n",
      "COLLECT loop time: 152.01213000000098\n",
      "TRAIN loop time: 0.5761351000001014\n",
      "Iter 114 | replay=50000 | train_return_mean=-86.87 | last_loss=0.030052702873945236\n",
      "main loop iter: 115\n",
      "time: 8254.4645523\n",
      "COLLECT loop time: 102.5726964000005\n",
      "TRAIN loop time: 0.5563692999985506\n",
      "Iter 115 | replay=50000 | train_return_mean=-4.80 | last_loss=0.029665209352970123\n",
      "main loop iter: 116\n",
      "time: 8357.5940636\n",
      "COLLECT loop time: 108.2442074999999\n",
      "TRAIN loop time: 0.4704323000005388\n",
      "Iter 116 | replay=50000 | train_return_mean=-63.99 | last_loss=0.025430921465158463\n",
      "main loop iter: 117\n",
      "time: 8466.3090313\n",
      "COLLECT loop time: 105.76603030000115\n",
      "TRAIN loop time: 0.47683649999999034\n",
      "Iter 117 | replay=50000 | train_return_mean=-12.31 | last_loss=0.029923973605036736\n",
      "main loop iter: 118\n",
      "time: 8572.5522853\n",
      "COLLECT loop time: 109.35611419999987\n",
      "TRAIN loop time: 0.5666396999986318\n",
      "Iter 118 | replay=50000 | train_return_mean=-26.62 | last_loss=0.02435845509171486\n",
      "main loop iter: 119\n",
      "time: 8682.4754683\n",
      "COLLECT loop time: 175.2630138000004\n",
      "TRAIN loop time: 0.5454609999997047\n",
      "Iter 119 | replay=50000 | train_return_mean=-95.55 | last_loss=0.02335640788078308\n",
      "main loop iter: 120\n",
      "time: 8858.2842879\n",
      "COLLECT loop time: 85.5099551000003\n",
      "TRAIN loop time: 0.5244302999999491\n",
      "Iter 120 | replay=50000 | train_return_mean=-24.57 | last_loss=0.022054031491279602\n",
      "main loop iter: 121\n",
      "time: 8944.3189699\n",
      "COLLECT loop time: 74.186671200001\n",
      "TRAIN loop time: 0.5616593999984616\n",
      "Iter 121 | replay=50000 | train_return_mean=2.23 | last_loss=0.019109681248664856\n",
      "main loop iter: 122\n",
      "time: 9019.0677279\n",
      "COLLECT loop time: 129.21812359999967\n",
      "TRAIN loop time: 0.5561740000011923\n",
      "Iter 122 | replay=50000 | train_return_mean=-3.96 | last_loss=0.025488365441560745\n",
      "main loop iter: 123\n",
      "time: 9148.8423502\n",
      "COLLECT loop time: 136.3159300999996\n",
      "TRAIN loop time: 0.5646514999989449\n",
      "Iter 123 | replay=50000 | train_return_mean=-52.13 | last_loss=0.024877268821001053\n",
      "main loop iter: 124\n",
      "time: 9285.723283899999\n",
      "COLLECT loop time: 67.29322649999995\n",
      "TRAIN loop time: 0.5258680000006279\n",
      "Iter 124 | replay=50000 | train_return_mean=-9.49 | last_loss=0.020455453544855118\n",
      "main loop iter: 125\n",
      "time: 9353.542741\n",
      "COLLECT loop time: 162.10279939999964\n",
      "TRAIN loop time: 0.5662095000006957\n",
      "EVAL time: 1023.8325543999999\n",
      "[Eval it=125] R=-104.14±133.27 succ=0.34 coll=0.00 max=0.66 len_suc=30.4 len_col=0.0 \n",
      "Iter 125 | replay=50000 | train_return_mean=-114.32 | last_loss=0.016308538615703583\n",
      "main loop iter: 126\n",
      "time: 10540.044719\n",
      "COLLECT loop time: 150.47409899999911\n",
      "TRAIN loop time: 0.4798303000025044\n",
      "Iter 126 | replay=50000 | train_return_mean=-115.76 | last_loss=0.013123026117682457\n",
      "main loop iter: 127\n",
      "time: 10690.998983200001\n",
      "COLLECT loop time: 49.00343359999897\n",
      "TRAIN loop time: 0.5990320999990217\n",
      "Iter 127 | replay=50000 | train_return_mean=13.45 | last_loss=0.011905492283403873\n",
      "main loop iter: 128\n",
      "time: 10740.6017462\n",
      "COLLECT loop time: 79.60200039999836\n",
      "TRAIN loop time: 0.5967146000002685\n",
      "Iter 128 | replay=50000 | train_return_mean=-43.32 | last_loss=0.009916495531797409\n",
      "main loop iter: 129\n",
      "time: 10820.8007959\n",
      "COLLECT loop time: 166.91840749999756\n",
      "TRAIN loop time: 0.4780713000000105\n",
      "Iter 129 | replay=50000 | train_return_mean=-142.50 | last_loss=0.009048054926097393\n",
      "main loop iter: 130\n",
      "time: 10988.197628\n",
      "COLLECT loop time: 66.482441199998\n",
      "TRAIN loop time: 0.4820770000005723\n",
      "Iter 130 | replay=50000 | train_return_mean=27.23 | last_loss=0.009344037622213364\n",
      "main loop iter: 131\n",
      "time: 11055.1625053\n",
      "COLLECT loop time: 158.22250219999842\n",
      "TRAIN loop time: 0.5718206000019563\n",
      "Iter 131 | replay=50000 | train_return_mean=-53.92 | last_loss=0.008567916229367256\n",
      "main loop iter: 132\n",
      "time: 11213.957274399998\n",
      "COLLECT loop time: 104.5066422000018\n",
      "TRAIN loop time: 0.6239042000015615\n",
      "Iter 132 | replay=50000 | train_return_mean=-4.97 | last_loss=0.008379396051168442\n",
      "main loop iter: 133\n",
      "time: 11319.088197799998\n",
      "COLLECT loop time: 86.01056770000287\n",
      "TRAIN loop time: 0.48892049999994924\n",
      "Iter 133 | replay=50000 | train_return_mean=-25.19 | last_loss=0.00731493066996336\n",
      "main loop iter: 134\n",
      "time: 11405.587961\n",
      "COLLECT loop time: 119.0723433000021\n",
      "TRAIN loop time: 0.5956576999997196\n",
      "Iter 134 | replay=50000 | train_return_mean=-45.43 | last_loss=0.007005523890256882\n",
      "main loop iter: 135\n",
      "time: 11525.2563354\n",
      "COLLECT loop time: 115.01139189999958\n",
      "TRAIN loop time: 0.5947493000021495\n",
      "Iter 135 | replay=50000 | train_return_mean=-26.31 | last_loss=0.011743023991584778\n",
      "main loop iter: 136\n",
      "time: 11640.862789199999\n",
      "COLLECT loop time: 115.01594540000224\n",
      "TRAIN loop time: 0.6173423000000184\n",
      "Iter 136 | replay=50000 | train_return_mean=-27.92 | last_loss=0.008119659498333931\n",
      "main loop iter: 137\n",
      "time: 11756.496460199998\n",
      "COLLECT loop time: 79.0389849000021\n",
      "TRAIN loop time: 0.6149206999980379\n",
      "Iter 137 | replay=50000 | train_return_mean=-26.47 | last_loss=0.006203414406627417\n",
      "main loop iter: 138\n",
      "time: 11836.150798599998\n",
      "COLLECT loop time: 76.451362900003\n",
      "TRAIN loop time: 0.47013999999762746\n",
      "Iter 138 | replay=50000 | train_return_mean=28.27 | last_loss=0.009013991802930832\n",
      "main loop iter: 139\n",
      "time: 11913.072694\n",
      "COLLECT loop time: 134.00114459999895\n",
      "TRAIN loop time: 0.613321900000301\n",
      "Iter 139 | replay=50000 | train_return_mean=-66.44 | last_loss=0.004933537449687719\n",
      "main loop iter: 140\n",
      "time: 12047.687542599999\n",
      "COLLECT loop time: 122.1872970000004\n",
      "TRAIN loop time: 0.651577399999951\n",
      "Iter 140 | replay=50000 | train_return_mean=-19.17 | last_loss=0.003403083421289921\n",
      "main loop iter: 141\n",
      "time: 12170.5267918\n",
      "COLLECT loop time: 181.3348862999992\n",
      "TRAIN loop time: 0.6162322999989556\n",
      "Iter 141 | replay=50000 | train_return_mean=-85.22 | last_loss=0.0030810441821813583\n",
      "main loop iter: 142\n",
      "time: 12352.478264399999\n",
      "COLLECT loop time: 148.27136240000254\n",
      "TRAIN loop time: 0.6283274999987043\n",
      "Iter 142 | replay=50000 | train_return_mean=-86.04 | last_loss=0.003606538288295269\n",
      "main loop iter: 143\n",
      "time: 12501.3783766\n",
      "COLLECT loop time: 139.57499520000056\n",
      "TRAIN loop time: 0.6289985000003071\n",
      "Iter 143 | replay=50000 | train_return_mean=-74.43 | last_loss=0.005472946912050247\n",
      "main loop iter: 144\n",
      "time: 12641.582789999999\n",
      "COLLECT loop time: 131.62061370000083\n",
      "TRAIN loop time: 0.49036049999995157\n",
      "Iter 144 | replay=50000 | train_return_mean=-37.50 | last_loss=0.004833623766899109\n",
      "main loop iter: 145\n",
      "time: 12773.6940351\n",
      "COLLECT loop time: 74.01757200000065\n",
      "TRAIN loop time: 0.6105384000002232\n",
      "Iter 145 | replay=50000 | train_return_mean=16.49 | last_loss=0.004335771314799786\n",
      "main loop iter: 146\n",
      "time: 12848.322530799998\n",
      "COLLECT loop time: 121.44574620000276\n",
      "TRAIN loop time: 0.6128091999999015\n",
      "Iter 146 | replay=50000 | train_return_mean=-31.43 | last_loss=0.004065897781401873\n",
      "main loop iter: 147\n",
      "time: 12970.3814421\n",
      "COLLECT loop time: 144.89986829999907\n",
      "TRAIN loop time: 0.6001255999981367\n",
      "Iter 147 | replay=50000 | train_return_mean=-52.71 | last_loss=0.003799861529842019\n",
      "main loop iter: 148\n",
      "time: 13115.881880899999\n",
      "COLLECT loop time: 101.53500899999926\n",
      "TRAIN loop time: 0.6213330000027781\n",
      "Iter 148 | replay=50000 | train_return_mean=-27.41 | last_loss=0.004531696438789368\n",
      "main loop iter: 149\n",
      "time: 13218.0385892\n",
      "COLLECT loop time: 42.95589860000109\n",
      "TRAIN loop time: 0.5449040999992576\n",
      "Iter 149 | replay=50000 | train_return_mean=39.42 | last_loss=0.003722198773175478\n",
      "main loop iter: 150\n",
      "time: 13261.5397966\n",
      "COLLECT loop time: 119.047677999999\n",
      "TRAIN loop time: 0.6358684000006178\n",
      "EVAL time: 864.3987587999982\n",
      "[Eval it=150] R=-63.82±142.82 succ=0.48 coll=0.00 max=0.52 len_suc=25.3 len_col=0.0 \n",
      "Iter 150 | replay=50000 | train_return_mean=-33.16 | last_loss=0.003413226455450058\n",
      "main loop iter: 151\n",
      "time: 14245.622612000001\n",
      "COLLECT loop time: 156.7340019000003\n",
      "TRAIN loop time: 0.5892215999992914\n",
      "Iter 151 | replay=50000 | train_return_mean=-94.14 | last_loss=0.009363770484924316\n",
      "main loop iter: 152\n",
      "time: 14402.9462219\n",
      "COLLECT loop time: 90.07194700000036\n",
      "TRAIN loop time: 0.5961740999991889\n",
      "Iter 152 | replay=50000 | train_return_mean=2.57 | last_loss=0.005180186592042446\n",
      "main loop iter: 153\n",
      "time: 14493.614775799999\n",
      "COLLECT loop time: 107.94934230000217\n",
      "TRAIN loop time: 0.5282106999984535\n",
      "Iter 153 | replay=50000 | train_return_mean=-28.89 | last_loss=0.0038901057559996843\n",
      "main loop iter: 154\n",
      "time: 14602.0927311\n",
      "COLLECT loop time: 109.58575180000116\n",
      "TRAIN loop time: 0.5142801000001782\n",
      "Iter 154 | replay=50000 | train_return_mean=-25.92 | last_loss=0.013572122901678085\n",
      "main loop iter: 155\n",
      "time: 14712.1930748\n",
      "COLLECT loop time: 108.89863650000188\n",
      "TRAIN loop time: 0.5736603999976069\n",
      "Iter 155 | replay=50000 | train_return_mean=0.69 | last_loss=0.004742785356938839\n",
      "main loop iter: 156\n",
      "time: 14821.665845000001\n",
      "COLLECT loop time: 109.97147429999677\n",
      "TRAIN loop time: 0.627273600002809\n",
      "Iter 156 | replay=50000 | train_return_mean=-43.33 | last_loss=0.011568784713745117\n",
      "main loop iter: 157\n",
      "time: 14932.265205999998\n",
      "COLLECT loop time: 96.30765200000315\n",
      "TRAIN loop time: 0.6025342999964778\n",
      "Iter 157 | replay=50000 | train_return_mean=-29.19 | last_loss=0.008190013468265533\n",
      "main loop iter: 158\n",
      "time: 15029.175794099998\n",
      "COLLECT loop time: 181.00684940000065\n",
      "TRAIN loop time: 0.47815000000264263\n",
      "Iter 158 | replay=50000 | train_return_mean=-92.54 | last_loss=0.008738188073039055\n",
      "main loop iter: 159\n",
      "time: 15210.6610995\n",
      "COLLECT loop time: 81.65359929999977\n",
      "TRAIN loop time: 0.5985538000022643\n",
      "Iter 159 | replay=50000 | train_return_mean=-0.50 | last_loss=0.007857510820031166\n",
      "main loop iter: 160\n",
      "time: 15292.913716500001\n",
      "COLLECT loop time: 178.29210359999706\n",
      "TRAIN loop time: 0.5954448000011325\n",
      "Iter 160 | replay=50000 | train_return_mean=-82.40 | last_loss=0.00870433822274208\n",
      "main loop iter: 161\n",
      "time: 15471.801665500001\n",
      "COLLECT loop time: 167.11396239999885\n",
      "TRAIN loop time: 0.5339505000010831\n",
      "Iter 161 | replay=50000 | train_return_mean=-85.44 | last_loss=0.007927367463707924\n",
      "main loop iter: 162\n",
      "time: 15639.449896299999\n",
      "COLLECT loop time: 110.81187670000145\n",
      "TRAIN loop time: 0.5891874000008102\n",
      "Iter 162 | replay=50000 | train_return_mean=-19.37 | last_loss=0.02199384942650795\n",
      "main loop iter: 163\n",
      "time: 15750.851280199999\n",
      "COLLECT loop time: 90.46219950000159\n",
      "TRAIN loop time: 0.5777037999978347\n",
      "Iter 163 | replay=50000 | train_return_mean=-17.60 | last_loss=0.015702592208981514\n",
      "main loop iter: 164\n",
      "time: 15841.891616300001\n",
      "COLLECT loop time: 135.1285360999973\n",
      "TRAIN loop time: 0.5832613000020501\n",
      "Iter 164 | replay=50000 | train_return_mean=-54.02 | last_loss=0.018408585339784622\n",
      "main loop iter: 165\n",
      "time: 15977.603854799998\n",
      "COLLECT loop time: 133.4377209000013\n",
      "TRAIN loop time: 0.4440826999998535\n",
      "Iter 165 | replay=50000 | train_return_mean=-20.59 | last_loss=0.0144516471773386\n",
      "main loop iter: 166\n",
      "time: 16111.485931199999\n",
      "COLLECT loop time: 151.10261150000224\n",
      "TRAIN loop time: 0.6065415999983088\n",
      "Iter 166 | replay=50000 | train_return_mean=-50.87 | last_loss=0.011156197637319565\n",
      "main loop iter: 167\n",
      "time: 16263.195506099999\n",
      "COLLECT loop time: 160.4529536000009\n",
      "TRAIN loop time: 0.617923999998311\n",
      "Iter 167 | replay=50000 | train_return_mean=-56.32 | last_loss=0.009420459158718586\n",
      "main loop iter: 168\n",
      "time: 16424.2668174\n",
      "COLLECT loop time: 115.60484029999861\n",
      "TRAIN loop time: 0.5966425000005984\n",
      "Iter 168 | replay=50000 | train_return_mean=-57.92 | last_loss=0.007659071125090122\n",
      "main loop iter: 169\n",
      "time: 16540.468736199997\n",
      "COLLECT loop time: 99.92715650000173\n",
      "TRAIN loop time: 0.6061747999992804\n",
      "Iter 169 | replay=50000 | train_return_mean=9.35 | last_loss=0.00870975200086832\n",
      "main loop iter: 170\n",
      "time: 16641.002497299996\n",
      "COLLECT loop time: 77.50738590000037\n",
      "TRAIN loop time: 0.4917234999993525\n",
      "Iter 170 | replay=50000 | train_return_mean=25.69 | last_loss=0.006791297346353531\n",
      "main loop iter: 171\n",
      "time: 16719.001921900002\n",
      "COLLECT loop time: 60.659422699998686\n",
      "TRAIN loop time: 0.4654961000014737\n",
      "Iter 171 | replay=50000 | train_return_mean=27.95 | last_loss=0.005765407346189022\n",
      "main loop iter: 172\n",
      "time: 16780.127184099998\n",
      "COLLECT loop time: 110.3667717999997\n",
      "TRAIN loop time: 0.4580722999999125\n",
      "Iter 172 | replay=50000 | train_return_mean=-36.17 | last_loss=0.005531612783670425\n",
      "main loop iter: 173\n",
      "time: 16890.952364800003\n",
      "COLLECT loop time: 102.17640559999927\n",
      "TRAIN loop time: 0.40187149999837857\n",
      "Iter 173 | replay=50000 | train_return_mean=-25.33 | last_loss=0.005873621441423893\n",
      "main loop iter: 174\n",
      "time: 16993.530937099997\n",
      "COLLECT loop time: 118.91463099999964\n",
      "TRAIN loop time: 0.4017304000008153\n",
      "Iter 174 | replay=50000 | train_return_mean=-77.51 | last_loss=0.004518219735473394\n",
      "main loop iter: 175\n",
      "time: 17112.8475901\n",
      "COLLECT loop time: 166.8108843000009\n",
      "TRAIN loop time: 0.4568182999973942\n",
      "EVAL time: 817.1250046999994\n",
      "[Eval it=175] R=-81.78±141.94 succ=0.42 coll=0.00 max=0.58 len_suc=26.6 len_col=0.0 \n",
      "Iter 175 | replay=50000 | train_return_mean=-99.56 | last_loss=0.004269039258360863\n",
      "main loop iter: 176\n",
      "time: 18097.2407228\n",
      "COLLECT loop time: 192.8704953000015\n",
      "TRAIN loop time: 0.5087421999996877\n",
      "Iter 176 | replay=50000 | train_return_mean=-151.77 | last_loss=0.004161881748586893\n",
      "main loop iter: 177\n",
      "time: 18290.620255299997\n",
      "COLLECT loop time: 90.67273900000146\n",
      "TRAIN loop time: 0.3943223999995098\n",
      "Iter 177 | replay=50000 | train_return_mean=-28.29 | last_loss=0.002656049793586135\n",
      "main loop iter: 178\n",
      "time: 18381.687643600002\n",
      "COLLECT loop time: 85.65628880000077\n",
      "TRAIN loop time: 0.4531448999987333\n",
      "Iter 178 | replay=50000 | train_return_mean=-52.08 | last_loss=0.0023365914821624756\n",
      "main loop iter: 179\n",
      "time: 18467.797375399998\n",
      "COLLECT loop time: 100.47001349999846\n",
      "TRAIN loop time: 0.4628855000009935\n",
      "Iter 179 | replay=50000 | train_return_mean=-2.05 | last_loss=0.003499615238979459\n",
      "main loop iter: 180\n",
      "time: 18568.730729299998\n",
      "COLLECT loop time: 83.14040709999972\n",
      "TRAIN loop time: 0.4531940000015311\n",
      "Iter 180 | replay=50000 | train_return_mean=-21.76 | last_loss=0.0029820376075804234\n",
      "main loop iter: 181\n",
      "time: 18652.324684500003\n",
      "COLLECT loop time: 106.50513629999841\n",
      "TRAIN loop time: 0.381650899998931\n",
      "Iter 181 | replay=50000 | train_return_mean=-50.97 | last_loss=0.005218475125730038\n",
      "main loop iter: 182\n",
      "time: 18759.211736799996\n",
      "COLLECT loop time: 133.01637590000246\n",
      "TRAIN loop time: 0.4045871999987867\n",
      "Iter 182 | replay=50000 | train_return_mean=-64.05 | last_loss=0.0031715682707726955\n",
      "main loop iter: 183\n",
      "time: 18892.633047099996\n",
      "COLLECT loop time: 23.567152100000385\n",
      "TRAIN loop time: 0.424984699999186\n",
      "Iter 183 | replay=50000 | train_return_mean=83.46 | last_loss=0.002650309819728136\n",
      "main loop iter: 184\n",
      "time: 18916.625481900002\n",
      "COLLECT loop time: 97.75591119999808\n",
      "TRAIN loop time: 0.4053149999999732\n",
      "Iter 184 | replay=50000 | train_return_mean=-9.99 | last_loss=0.0021976951975375414\n",
      "main loop iter: 185\n",
      "time: 19014.786997299998\n",
      "COLLECT loop time: 129.12044099999912\n",
      "TRAIN loop time: 0.4030879999991157\n",
      "Iter 185 | replay=50000 | train_return_mean=-44.31 | last_loss=0.0026547142770141363\n",
      "main loop iter: 186\n",
      "time: 19144.310835700002\n",
      "COLLECT loop time: 105.2978331000013\n",
      "TRAIN loop time: 0.38860269999713637\n",
      "Iter 186 | replay=50000 | train_return_mean=-52.56 | last_loss=0.0015934661496430635\n",
      "main loop iter: 187\n",
      "time: 19249.997428199997\n",
      "COLLECT loop time: 84.40067640000052\n",
      "TRAIN loop time: 0.40431549999993877\n",
      "Iter 187 | replay=50000 | train_return_mean=-43.29 | last_loss=0.0027935197576880455\n",
      "main loop iter: 188\n",
      "time: 19334.8027208\n",
      "COLLECT loop time: 122.88768789999813\n",
      "TRAIN loop time: 0.4608743000026152\n",
      "Iter 188 | replay=50000 | train_return_mean=-35.32 | last_loss=0.002376929856836796\n",
      "main loop iter: 189\n",
      "time: 19458.151613399998\n",
      "COLLECT loop time: 108.74101109999901\n",
      "TRAIN loop time: 0.4276833000003535\n",
      "Iter 189 | replay=50000 | train_return_mean=-27.72 | last_loss=0.002183766569942236\n",
      "main loop iter: 190\n",
      "time: 19567.3206517\n",
      "COLLECT loop time: 68.62526410000282\n",
      "TRAIN loop time: 0.41267729999890435\n",
      "Iter 190 | replay=50000 | train_return_mean=-16.38 | last_loss=0.001814978662878275\n",
      "main loop iter: 191\n",
      "time: 19636.3588923\n",
      "COLLECT loop time: 102.28741760000048\n",
      "TRAIN loop time: 0.415112799997587\n",
      "Iter 191 | replay=50000 | train_return_mean=-2.89 | last_loss=0.004741385579109192\n",
      "main loop iter: 192\n",
      "time: 19739.061777900002\n",
      "COLLECT loop time: 62.225379799998336\n",
      "TRAIN loop time: 0.469679100002395\n",
      "Iter 192 | replay=50000 | train_return_mean=20.75 | last_loss=0.003639967180788517\n",
      "main loop iter: 193\n",
      "time: 19801.757232099997\n",
      "COLLECT loop time: 112.56296070000099\n",
      "TRAIN loop time: 0.449433499998122\n",
      "Iter 193 | replay=50000 | train_return_mean=-37.08 | last_loss=0.0037457142025232315\n",
      "main loop iter: 194\n",
      "time: 19914.7697818\n",
      "COLLECT loop time: 52.32835580000028\n",
      "TRAIN loop time: 0.4228818000010506\n",
      "Iter 194 | replay=50000 | train_return_mean=8.43 | last_loss=0.0023198160342872143\n",
      "main loop iter: 195\n",
      "time: 19967.521326100003\n",
      "COLLECT loop time: 74.1455621999994\n",
      "TRAIN loop time: 0.4046608999997261\n",
      "Iter 195 | replay=50000 | train_return_mean=47.40 | last_loss=0.0021800934337079525\n",
      "main loop iter: 196\n",
      "time: 20042.0719339\n",
      "COLLECT loop time: 59.27412229999754\n",
      "TRAIN loop time: 0.40573960000256193\n",
      "Iter 196 | replay=50000 | train_return_mean=43.61 | last_loss=0.0013322876766324043\n",
      "main loop iter: 197\n",
      "time: 20101.752116999996\n",
      "COLLECT loop time: 81.68126300000222\n",
      "TRAIN loop time: 0.4245327999997244\n",
      "Iter 197 | replay=50000 | train_return_mean=2.34 | last_loss=0.0011610444635152817\n",
      "main loop iter: 198\n",
      "time: 20183.858210500002\n",
      "COLLECT loop time: 101.82564949999869\n",
      "TRAIN loop time: 0.44099610000193934\n",
      "Iter 198 | replay=50000 | train_return_mean=-18.34 | last_loss=0.001410824479535222\n",
      "main loop iter: 199\n",
      "time: 20286.1252148\n",
      "COLLECT loop time: 113.90300500000012\n",
      "TRAIN loop time: 0.3984682000009343\n",
      "Iter 199 | replay=50000 | train_return_mean=-9.28 | last_loss=0.0008120010606944561\n",
      "main loop iter: 200\n",
      "time: 20400.4269796\n",
      "COLLECT loop time: 116.63613500000065\n",
      "TRAIN loop time: 0.3997243999983766\n",
      "EVAL time: 843.0408608000034\n",
      "[Eval it=200] R=-71.30±143.28 succ=0.44 coll=0.00 max=0.56 len_suc=18.5 len_col=0.0 \n",
      "Iter 200 | replay=50000 | train_return_mean=-42.29 | last_loss=0.0013904138468205929\n",
      "main loop iter: 201\n",
      "time: 21360.504290700002\n",
      "COLLECT loop time: 148.13388599999962\n",
      "TRAIN loop time: 0.4435778000006394\n",
      "Iter 201 | replay=50000 | train_return_mean=-62.29 | last_loss=0.0010492122964933515\n",
      "main loop iter: 202\n",
      "time: 21509.082139\n",
      "COLLECT loop time: 16.35669929999858\n",
      "TRAIN loop time: 0.46465510000052745\n",
      "Iter 202 | replay=50000 | train_return_mean=51.31 | last_loss=0.0009708090219646692\n",
      "main loop iter: 203\n",
      "time: 21525.903879600002\n",
      "COLLECT loop time: 114.7319127999981\n",
      "TRAIN loop time: 0.49033330000020214\n",
      "Iter 203 | replay=50000 | train_return_mean=-42.74 | last_loss=0.0009292679606005549\n",
      "main loop iter: 204\n",
      "time: 21641.126547699998\n",
      "COLLECT loop time: 141.71385699999882\n",
      "TRAIN loop time: 0.4851830000006885\n",
      "Iter 204 | replay=50000 | train_return_mean=-35.49 | last_loss=0.0010772040113806725\n",
      "main loop iter: 205\n",
      "time: 21783.325982399998\n",
      "COLLECT loop time: 87.59974629999851\n",
      "TRAIN loop time: 0.5083248000009917\n",
      "Iter 205 | replay=50000 | train_return_mean=-15.73 | last_loss=0.0015799335669726133\n",
      "main loop iter: 206\n",
      "time: 21871.4345062\n",
      "COLLECT loop time: 199.29106059999685\n",
      "TRAIN loop time: 0.517663900001935\n",
      "Iter 206 | replay=50000 | train_return_mean=-113.25 | last_loss=0.0043295640498399734\n",
      "main loop iter: 207\n",
      "time: 22071.243713999997\n",
      "COLLECT loop time: 117.78892690000066\n",
      "TRAIN loop time: 0.4628468000009889\n",
      "Iter 207 | replay=50000 | train_return_mean=-92.02 | last_loss=0.07329615950584412\n",
      "main loop iter: 208\n",
      "time: 22189.495876399997\n",
      "COLLECT loop time: 128.37952240000232\n",
      "TRAIN loop time: 0.3770212999988871\n",
      "Iter 208 | replay=50000 | train_return_mean=-36.53 | last_loss=0.09057725220918655\n",
      "main loop iter: 209\n",
      "time: 22318.252729699998\n",
      "COLLECT loop time: 57.94647229999828\n",
      "TRAIN loop time: 0.371104000001651\n",
      "Iter 209 | replay=50000 | train_return_mean=29.51 | last_loss=0.0865737646818161\n",
      "main loop iter: 210\n",
      "time: 22376.5705771\n",
      "COLLECT loop time: 131.36775849999685\n",
      "TRAIN loop time: 0.38740510000206996\n",
      "Iter 210 | replay=50000 | train_return_mean=-88.73 | last_loss=0.0819343775510788\n",
      "main loop iter: 211\n",
      "time: 22508.3260838\n",
      "COLLECT loop time: 98.04646069999944\n",
      "TRAIN loop time: 0.3765653000009479\n",
      "Iter 211 | replay=50000 | train_return_mean=-1.08 | last_loss=0.0830431878566742\n",
      "main loop iter: 212\n",
      "time: 22606.7492612\n",
      "COLLECT loop time: 105.81225029999769\n",
      "TRAIN loop time: 0.38125790000049165\n",
      "Iter 212 | replay=50000 | train_return_mean=-45.00 | last_loss=0.012199006974697113\n",
      "main loop iter: 213\n",
      "time: 22712.942891500003\n",
      "COLLECT loop time: 102.5855816000003\n",
      "TRAIN loop time: 0.41060599999764236\n",
      "Iter 213 | replay=50000 | train_return_mean=-60.93 | last_loss=0.011185593903064728\n",
      "main loop iter: 214\n",
      "time: 22815.9394654\n",
      "COLLECT loop time: 73.32968529999926\n",
      "TRAIN loop time: 0.3993841000010434\n",
      "Iter 214 | replay=50000 | train_return_mean=33.13 | last_loss=0.009215140715241432\n",
      "main loop iter: 215\n",
      "time: 22889.668868599998\n",
      "COLLECT loop time: 107.92992579999918\n",
      "TRAIN loop time: 0.44341329999951995\n",
      "Iter 215 | replay=50000 | train_return_mean=-73.38 | last_loss=0.01445525698363781\n",
      "main loop iter: 216\n",
      "time: 22998.0424775\n",
      "COLLECT loop time: 157.72029569999722\n",
      "TRAIN loop time: 0.4230641000031028\n",
      "Iter 216 | replay=50000 | train_return_mean=-89.50 | last_loss=0.009579388424754143\n",
      "main loop iter: 217\n",
      "time: 23156.1861948\n",
      "COLLECT loop time: 98.52990460000001\n",
      "TRAIN loop time: 0.41286350000154926\n",
      "Iter 217 | replay=50000 | train_return_mean=-26.34 | last_loss=0.008379567414522171\n",
      "main loop iter: 218\n",
      "time: 23255.129295400002\n",
      "COLLECT loop time: 91.005526500001\n",
      "TRAIN loop time: 0.41286289999698056\n",
      "Iter 218 | replay=50000 | train_return_mean=7.41 | last_loss=0.007939876988530159\n",
      "main loop iter: 219\n",
      "time: 23346.5479383\n",
      "COLLECT loop time: 95.21398749999935\n",
      "TRAIN loop time: 0.408825300000899\n",
      "Iter 219 | replay=50000 | train_return_mean=-19.16 | last_loss=0.011831026524305344\n",
      "main loop iter: 220\n",
      "time: 23442.1711954\n",
      "COLLECT loop time: 90.4901652999979\n",
      "TRAIN loop time: 0.40089760000046226\n",
      "Iter 220 | replay=50000 | train_return_mean=-28.07 | last_loss=0.00794666726142168\n",
      "main loop iter: 221\n",
      "time: 23533.0625802\n",
      "COLLECT loop time: 91.51780239999789\n",
      "TRAIN loop time: 0.4068918000011763\n",
      "Iter 221 | replay=50000 | train_return_mean=-49.82 | last_loss=0.006801614537835121\n",
      "main loop iter: 222\n",
      "time: 23624.987608900003\n",
      "COLLECT loop time: 90.10399999999936\n",
      "TRAIN loop time: 0.41271710000000894\n",
      "Iter 222 | replay=50000 | train_return_mean=-3.16 | last_loss=0.005766835063695908\n",
      "main loop iter: 223\n",
      "time: 23715.504617699997\n",
      "COLLECT loop time: 108.23595900000146\n",
      "TRAIN loop time: 0.40780919999815524\n",
      "Iter 223 | replay=50000 | train_return_mean=-22.73 | last_loss=0.0039179641753435135\n",
      "main loop iter: 224\n",
      "time: 23824.148699999998\n",
      "COLLECT loop time: 155.551963599999\n",
      "TRAIN loop time: 0.37693819999913103\n",
      "Iter 224 | replay=50000 | train_return_mean=-84.76 | last_loss=0.004477489739656448\n",
      "main loop iter: 225\n",
      "time: 23980.077867400003\n",
      "COLLECT loop time: 97.25463099999979\n",
      "TRAIN loop time: 0.38319399999818415\n",
      "EVAL time: 456.7550097000021\n",
      "[Eval it=225] R=5.14±129.95 succ=0.72 coll=0.00 max=0.28 len_suc=23.7 len_col=0.0 \n",
      "Iter 225 | replay=50000 | train_return_mean=-58.31 | last_loss=0.002755136229097843\n",
      "main loop iter: 226\n",
      "time: 24534.471093699998\n",
      "COLLECT loop time: 100.24477159999878\n",
      "TRAIN loop time: 0.38397880000047735\n",
      "Iter 226 | replay=50000 | train_return_mean=-31.76 | last_loss=0.0024473683442920446\n",
      "main loop iter: 227\n",
      "time: 24635.1001112\n",
      "COLLECT loop time: 51.4199492000007\n",
      "TRAIN loop time: 0.3888366999999562\n",
      "Iter 227 | replay=50000 | train_return_mean=30.28 | last_loss=0.0026829619891941547\n",
      "main loop iter: 228\n",
      "time: 24686.9092726\n",
      "COLLECT loop time: 132.15492200000153\n",
      "TRAIN loop time: 0.406744299998536\n",
      "Iter 228 | replay=50000 | train_return_mean=-101.13 | last_loss=0.0027312517631798983\n",
      "main loop iter: 229\n",
      "time: 24819.4712477\n",
      "COLLECT loop time: 112.5657328999987\n",
      "TRAIN loop time: 0.41483729999890784\n",
      "Iter 229 | replay=50000 | train_return_mean=-29.13 | last_loss=0.0027558475267142057\n",
      "main loop iter: 230\n",
      "time: 24932.452189099997\n",
      "COLLECT loop time: 62.18679279999924\n",
      "TRAIN loop time: 0.39058490000024904\n",
      "Iter 230 | replay=50000 | train_return_mean=9.15 | last_loss=0.0029849661514163017\n",
      "main loop iter: 231\n",
      "time: 24995.029837100003\n",
      "COLLECT loop time: 64.29419459999917\n",
      "TRAIN loop time: 0.40716369999790913\n",
      "Iter 231 | replay=50000 | train_return_mean=7.12 | last_loss=0.003143871668726206\n",
      "main loop iter: 232\n",
      "time: 25059.7316477\n",
      "COLLECT loop time: 71.89651650000087\n",
      "TRAIN loop time: 0.386541899999429\n",
      "Iter 232 | replay=50000 | train_return_mean=-11.57 | last_loss=0.0021748398430645466\n",
      "main loop iter: 233\n",
      "time: 25132.015060899997\n",
      "COLLECT loop time: 91.0473110999992\n",
      "TRAIN loop time: 0.4275182000019413\n",
      "Iter 233 | replay=50000 | train_return_mean=-5.40 | last_loss=0.005218161270022392\n",
      "main loop iter: 234\n",
      "time: 25223.4902009\n",
      "COLLECT loop time: 102.0127057000027\n",
      "TRAIN loop time: 0.3953862999987905\n",
      "Iter 234 | replay=50000 | train_return_mean=-21.56 | last_loss=0.003854900598526001\n",
      "main loop iter: 235\n",
      "time: 25325.8986497\n",
      "COLLECT loop time: 131.3174065000021\n",
      "TRAIN loop time: 0.4007287999993423\n",
      "Iter 235 | replay=50000 | train_return_mean=-48.15 | last_loss=0.003729881253093481\n",
      "main loop iter: 236\n",
      "time: 25457.617145199998\n",
      "COLLECT loop time: 46.09203630000047\n",
      "TRAIN loop time: 0.3962248999996518\n",
      "Iter 236 | replay=50000 | train_return_mean=54.96 | last_loss=0.0035746959038078785\n",
      "main loop iter: 237\n",
      "time: 25504.105669800003\n",
      "COLLECT loop time: 148.97791940000025\n",
      "TRAIN loop time: 0.4145422999972652\n",
      "Iter 237 | replay=50000 | train_return_mean=-84.69 | last_loss=0.0038617367390543222\n",
      "main loop iter: 238\n",
      "time: 25653.498448\n",
      "COLLECT loop time: 64.01875440000003\n",
      "TRAIN loop time: 0.38301549999960116\n",
      "Iter 238 | replay=50000 | train_return_mean=8.60 | last_loss=0.003495445242151618\n",
      "main loop iter: 239\n",
      "time: 25717.9005159\n",
      "COLLECT loop time: 144.66269699999975\n",
      "TRAIN loop time: 0.39118210000015097\n",
      "Iter 239 | replay=50000 | train_return_mean=-70.67 | last_loss=0.003943363204598427\n",
      "main loop iter: 240\n",
      "time: 25862.954668899998\n",
      "COLLECT loop time: 140.98503719999644\n",
      "TRAIN loop time: 0.3668653000058839\n",
      "Iter 240 | replay=50000 | train_return_mean=-70.80 | last_loss=0.004534435458481312\n",
      "main loop iter: 241\n",
      "time: 26004.3068344\n",
      "COLLECT loop time: 80.95876640000643\n",
      "TRAIN loop time: 0.3706679999959306\n",
      "Iter 241 | replay=50000 | train_return_mean=-40.28 | last_loss=0.004005751106888056\n",
      "main loop iter: 242\n",
      "time: 26085.6364206\n",
      "COLLECT loop time: 136.68791580000106\n",
      "TRAIN loop time: 0.35994899999786867\n",
      "Iter 242 | replay=50000 | train_return_mean=-81.56 | last_loss=0.0037390978541225195\n",
      "main loop iter: 243\n",
      "time: 26222.684557600005\n",
      "COLLECT loop time: 112.45086489999812\n",
      "TRAIN loop time: 0.3695109999971464\n",
      "Iter 243 | replay=50000 | train_return_mean=-57.07 | last_loss=0.003414406906813383\n",
      "main loop iter: 244\n",
      "time: 26335.505222600004\n",
      "COLLECT loop time: 71.04146000000037\n",
      "TRAIN loop time: 0.38001109999459004\n",
      "Iter 244 | replay=50000 | train_return_mean=-13.12 | last_loss=0.003215501783415675\n",
      "main loop iter: 245\n",
      "time: 26406.926985500002\n",
      "COLLECT loop time: 154.6179334999979\n",
      "TRAIN loop time: 0.36717530000169063\n",
      "Iter 245 | replay=50000 | train_return_mean=-124.15 | last_loss=0.0034211166203022003\n",
      "main loop iter: 246\n",
      "time: 26561.9123503\n",
      "COLLECT loop time: 126.13539589999709\n",
      "TRAIN loop time: 0.3611614000037662\n",
      "Iter 246 | replay=50000 | train_return_mean=-76.06 | last_loss=0.0030272160656750202\n",
      "main loop iter: 247\n",
      "time: 26688.409210700003\n",
      "COLLECT loop time: 131.45446770000126\n",
      "TRAIN loop time: 0.37048030000005383\n",
      "Iter 247 | replay=50000 | train_return_mean=-59.18 | last_loss=0.0030681276693940163\n",
      "main loop iter: 248\n",
      "time: 26820.2344058\n",
      "COLLECT loop time: 73.39902060000168\n",
      "TRAIN loop time: 0.36233609999908367\n",
      "Iter 248 | replay=50000 | train_return_mean=19.32 | last_loss=0.002792524406686425\n",
      "main loop iter: 249\n",
      "time: 26893.9960316\n",
      "COLLECT loop time: 67.02394230000209\n",
      "TRAIN loop time: 0.3777972999960184\n",
      "Iter 249 | replay=50000 | train_return_mean=32.36 | last_loss=0.003363527823239565\n",
      "main loop iter: 250\n",
      "time: 26961.3980459\n",
      "COLLECT loop time: 112.85234070000297\n",
      "TRAIN loop time: 0.3616057999970508\n",
      "EVAL time: 504.58366150000074\n",
      "[Eval it=250] R=-8.86±137.46 succ=0.66 coll=0.00 max=0.34 len_suc=20.3 len_col=0.0 \n",
      "Iter 250 | replay=50000 | train_return_mean=-40.10 | last_loss=0.00458901422098279\n",
      "main loop iter: 251\n",
      "time: 27579.1960309\n",
      "COLLECT loop time: 54.75618470000336\n",
      "TRAIN loop time: 0.3664158999963547\n",
      "Iter 251 | replay=50000 | train_return_mean=34.57 | last_loss=0.003480310318991542\n",
      "main loop iter: 252\n",
      "time: 27634.3188915\n",
      "COLLECT loop time: 46.022678900000756\n",
      "TRAIN loop time: 0.35760580000351183\n",
      "Iter 252 | replay=50000 | train_return_mean=35.00 | last_loss=0.0030401754193007946\n",
      "main loop iter: 253\n",
      "time: 27680.6994289\n",
      "COLLECT loop time: 43.59070710000378\n",
      "TRAIN loop time: 0.35550379999767756\n",
      "Iter 253 | replay=50000 | train_return_mean=57.86 | last_loss=0.002796964021399617\n",
      "main loop iter: 254\n",
      "time: 27724.645875200004\n",
      "COLLECT loop time: 106.19468849999976\n",
      "TRAIN loop time: 0.36259839999547694\n",
      "Iter 254 | replay=50000 | train_return_mean=-11.64 | last_loss=0.0029834555462002754\n",
      "main loop iter: 255\n",
      "time: 27831.203462900005\n",
      "COLLECT loop time: 151.74577139999747\n",
      "TRAIN loop time: 0.35959149999689544\n",
      "Iter 255 | replay=50000 | train_return_mean=-99.32 | last_loss=0.0028378597926348448\n",
      "main loop iter: 256\n",
      "time: 27983.308968700003\n",
      "COLLECT loop time: 118.08229819999542\n",
      "TRAIN loop time: 0.3733544000060647\n",
      "Iter 256 | replay=50000 | train_return_mean=-96.93 | last_loss=0.0037937909364700317\n",
      "main loop iter: 257\n",
      "time: 28101.765076000003\n",
      "COLLECT loop time: 94.7741559999995\n",
      "TRAIN loop time: 0.3889045999967493\n",
      "Iter 257 | replay=50000 | train_return_mean=-2.06 | last_loss=0.0032671215012669563\n",
      "main loop iter: 258\n",
      "time: 28196.928436000002\n",
      "COLLECT loop time: 110.8925784000021\n",
      "TRAIN loop time: 0.35934740000084275\n",
      "Iter 258 | replay=50000 | train_return_mean=-39.16 | last_loss=0.0028681473340839148\n",
      "main loop iter: 259\n",
      "time: 28308.1806576\n",
      "COLLECT loop time: 73.72963449999952\n",
      "TRAIN loop time: 0.3750711000029696\n",
      "Iter 259 | replay=50000 | train_return_mean=6.10 | last_loss=0.002731687854975462\n",
      "main loop iter: 260\n",
      "time: 28382.2856578\n",
      "COLLECT loop time: 65.4021825000018\n",
      "TRAIN loop time: 0.3763344000035431\n",
      "Iter 260 | replay=50000 | train_return_mean=26.13 | last_loss=0.0021872022189199924\n",
      "main loop iter: 261\n",
      "time: 28448.0644522\n",
      "COLLECT loop time: 139.64005270000052\n",
      "TRAIN loop time: 0.3667230999999447\n",
      "Iter 261 | replay=50000 | train_return_mean=-66.96 | last_loss=0.0028372262604534626\n",
      "main loop iter: 262\n",
      "time: 28588.0715166\n",
      "COLLECT loop time: 129.7614606999996\n",
      "TRAIN loop time: 0.3628428000010899\n",
      "Iter 262 | replay=50000 | train_return_mean=-53.88 | last_loss=0.004485650919377804\n",
      "main loop iter: 263\n",
      "time: 28718.196070500002\n",
      "COLLECT loop time: 47.30848330000299\n",
      "TRAIN loop time: 0.3789299999989453\n",
      "Iter 263 | replay=50000 | train_return_mean=53.47 | last_loss=0.003738498082384467\n",
      "main loop iter: 264\n",
      "time: 28765.8837317\n",
      "COLLECT loop time: 42.03069350000442\n",
      "TRAIN loop time: 0.363743699999759\n",
      "Iter 264 | replay=50000 | train_return_mean=56.61 | last_loss=0.0035240768920630217\n",
      "main loop iter: 265\n",
      "time: 28808.278431600003\n",
      "COLLECT loop time: 162.64338119999593\n",
      "TRAIN loop time: 0.39919080000254326\n",
      "Iter 265 | replay=50000 | train_return_mean=-130.97 | last_loss=0.0036875519435852766\n",
      "main loop iter: 266\n",
      "time: 28971.3213376\n",
      "COLLECT loop time: 46.40195360000507\n",
      "TRAIN loop time: 0.3826656999954139\n",
      "Iter 266 | replay=50000 | train_return_mean=36.64 | last_loss=0.003633385058492422\n",
      "main loop iter: 267\n",
      "time: 29018.1062416\n",
      "COLLECT loop time: 100.91418640000484\n",
      "TRAIN loop time: 0.37904770000022836\n",
      "Iter 267 | replay=50000 | train_return_mean=-5.64 | last_loss=0.003182551357895136\n",
      "main loop iter: 268\n",
      "time: 29119.399735799998\n",
      "COLLECT loop time: 122.04585690000386\n",
      "TRAIN loop time: 0.3837463000018033\n",
      "Iter 268 | replay=50000 | train_return_mean=-60.50 | last_loss=0.0030045490711927414\n",
      "main loop iter: 269\n",
      "time: 29241.829627400002\n",
      "COLLECT loop time: 80.30745249999745\n",
      "TRAIN loop time: 0.4062825000000885\n",
      "Iter 269 | replay=50000 | train_return_mean=24.15 | last_loss=0.002633357886224985\n",
      "main loop iter: 270\n",
      "time: 29322.543666800004\n",
      "COLLECT loop time: 26.32006719999481\n",
      "TRAIN loop time: 0.35775090000242926\n",
      "Iter 270 | replay=50000 | train_return_mean=82.53 | last_loss=0.002545336727052927\n",
      "main loop iter: 271\n",
      "time: 29349.221738\n",
      "COLLECT loop time: 157.36545879999903\n",
      "TRAIN loop time: 0.38211430000228574\n",
      "Iter 271 | replay=50000 | train_return_mean=-114.45 | last_loss=0.00714421272277832\n",
      "main loop iter: 272\n",
      "time: 29506.969590300003\n",
      "COLLECT loop time: 92.54659849999734\n",
      "TRAIN loop time: 0.36647800000355346\n",
      "Iter 272 | replay=50000 | train_return_mean=-12.00 | last_loss=0.007175576873123646\n",
      "main loop iter: 273\n",
      "time: 29599.882940900003\n",
      "COLLECT loop time: 120.49650139999721\n",
      "TRAIN loop time: 0.380285899998853\n",
      "Iter 273 | replay=50000 | train_return_mean=-85.37 | last_loss=0.0052634794265031815\n",
      "main loop iter: 274\n",
      "time: 29720.7600026\n",
      "COLLECT loop time: 159.60337040000013\n",
      "TRAIN loop time: 0.4119171999991522\n",
      "Iter 274 | replay=50000 | train_return_mean=-116.80 | last_loss=0.004580045118927956\n",
      "main loop iter: 275\n",
      "time: 29880.7755978\n",
      "COLLECT loop time: 164.81915170000138\n",
      "TRAIN loop time: 0.3554130000047735\n",
      "EVAL time: 661.6106404999955\n",
      "[Eval it=275] R=-55.36±146.14 succ=0.50 coll=0.00 max=0.50 len_suc=18.7 len_col=0.0 \n",
      "Iter 275 | replay=50000 | train_return_mean=-116.21 | last_loss=0.004344512242823839\n",
      "main loop iter: 276\n",
      "time: 30707.561197900002\n",
      "COLLECT loop time: 56.53161269999691\n",
      "TRAIN loop time: 0.359323000004224\n",
      "Iter 276 | replay=50000 | train_return_mean=-2.45 | last_loss=0.0035864708479493856\n",
      "main loop iter: 277\n",
      "time: 30764.452303\n",
      "COLLECT loop time: 82.24527510000189\n",
      "TRAIN loop time: 0.381392399998731\n",
      "Iter 277 | replay=50000 | train_return_mean=1.05 | last_loss=0.003215281292796135\n",
      "main loop iter: 278\n",
      "time: 30847.079316900003\n",
      "COLLECT loop time: 80.01951579999877\n",
      "TRAIN loop time: 0.40461900000082096\n",
      "Iter 278 | replay=50000 | train_return_mean=-7.17 | last_loss=0.0025621182285249233\n",
      "main loop iter: 279\n",
      "time: 30927.503825600004\n",
      "COLLECT loop time: 106.26673409999785\n",
      "TRAIN loop time: 0.40331940000032773\n",
      "Iter 279 | replay=50000 | train_return_mean=-72.04 | last_loss=0.0022816003765910864\n",
      "main loop iter: 280\n",
      "time: 31034.17415\n",
      "COLLECT loop time: 107.97088760000042\n",
      "TRAIN loop time: 0.37020070000289707\n",
      "Iter 280 | replay=50000 | train_return_mean=-54.36 | last_loss=0.002122344449162483\n",
      "main loop iter: 281\n",
      "time: 31142.515531000005\n",
      "COLLECT loop time: 187.60592239999824\n",
      "TRAIN loop time: 0.40735299999505514\n",
      "Iter 281 | replay=50000 | train_return_mean=-149.61 | last_loss=0.0015926153864711523\n",
      "main loop iter: 282\n",
      "time: 31330.52908\n",
      "COLLECT loop time: 115.89596829999937\n",
      "TRAIN loop time: 0.3757871999987401\n",
      "Iter 282 | replay=50000 | train_return_mean=-60.82 | last_loss=0.0013411014806479216\n",
      "main loop iter: 283\n",
      "time: 31446.8011741\n",
      "COLLECT loop time: 112.30394940000406\n",
      "TRAIN loop time: 0.39830259999871487\n",
      "Iter 283 | replay=50000 | train_return_mean=-47.12 | last_loss=0.0014719434548169374\n",
      "main loop iter: 284\n",
      "time: 31559.503698600005\n",
      "COLLECT loop time: 42.82991049999691\n",
      "TRAIN loop time: 0.4023254999992787\n",
      "Iter 284 | replay=50000 | train_return_mean=37.67 | last_loss=0.0010541046503931284\n",
      "main loop iter: 285\n",
      "time: 31602.736326600003\n",
      "COLLECT loop time: 123.52640819999942\n",
      "TRAIN loop time: 0.38476860000082524\n",
      "Iter 285 | replay=50000 | train_return_mean=-77.58 | last_loss=0.00708868820220232\n",
      "main loop iter: 286\n",
      "time: 31726.647770100004\n",
      "COLLECT loop time: 115.36569229999441\n",
      "TRAIN loop time: 0.3880554000061238\n",
      "Iter 286 | replay=50000 | train_return_mean=-49.45 | last_loss=0.006250135600566864\n",
      "main loop iter: 287\n",
      "time: 31842.401816600002\n",
      "COLLECT loop time: 124.69025210000109\n",
      "TRAIN loop time: 0.4178678999960539\n",
      "Iter 287 | replay=50000 | train_return_mean=-80.23 | last_loss=0.004524806514382362\n",
      "main loop iter: 288\n",
      "time: 31967.510293500003\n",
      "COLLECT loop time: 100.7420334999988\n",
      "TRAIN loop time: 0.38457740000012564\n",
      "Iter 288 | replay=50000 | train_return_mean=-4.96 | last_loss=0.003905384335666895\n",
      "main loop iter: 289\n",
      "time: 32068.6371728\n",
      "COLLECT loop time: 111.79488200000196\n",
      "TRAIN loop time: 0.40507549999892944\n",
      "Iter 289 | replay=50000 | train_return_mean=-59.80 | last_loss=0.0035787271335721016\n",
      "main loop iter: 290\n",
      "time: 32180.837472799998\n",
      "COLLECT loop time: 103.26732450000418\n",
      "TRAIN loop time: 0.4040423999977065\n",
      "Iter 290 | replay=50000 | train_return_mean=-26.81 | last_loss=0.004097131080925465\n",
      "main loop iter: 291\n",
      "time: 32284.509113500004\n",
      "COLLECT loop time: 149.4521500999981\n",
      "TRAIN loop time: 0.4114098999998532\n",
      "Iter 291 | replay=50000 | train_return_mean=-70.97 | last_loss=0.004211246967315674\n",
      "main loop iter: 292\n",
      "time: 32434.3729878\n",
      "COLLECT loop time: 62.745530100000906\n",
      "TRAIN loop time: 0.4149161999957869\n",
      "Iter 292 | replay=50000 | train_return_mean=31.15 | last_loss=0.0035154009237885475\n",
      "main loop iter: 293\n",
      "time: 32497.533735099998\n",
      "COLLECT loop time: 105.06766090000019\n",
      "TRAIN loop time: 0.38861480000196025\n",
      "Iter 293 | replay=50000 | train_return_mean=-27.28 | last_loss=0.004161981865763664\n",
      "main loop iter: 294\n",
      "time: 32602.990275800003\n",
      "COLLECT loop time: 118.0994251000011\n",
      "TRAIN loop time: 0.3983550999982981\n",
      "Iter 294 | replay=50000 | train_return_mean=-72.33 | last_loss=0.004362891428172588\n",
      "main loop iter: 295\n",
      "time: 32721.4883702\n",
      "COLLECT loop time: 77.07037639999908\n",
      "TRAIN loop time: 0.42323700000270037\n",
      "Iter 295 | replay=50000 | train_return_mean=5.35 | last_loss=0.0037012796383351088\n",
      "main loop iter: 296\n",
      "time: 32798.982321\n",
      "COLLECT loop time: 132.9291258000012\n",
      "TRAIN loop time: 0.3913828000004287\n",
      "Iter 296 | replay=50000 | train_return_mean=-54.92 | last_loss=0.003957531414926052\n",
      "main loop iter: 297\n",
      "time: 32932.303094300005\n",
      "COLLECT loop time: 103.58652259999508\n",
      "TRAIN loop time: 0.4005241999984719\n",
      "Iter 297 | replay=50000 | train_return_mean=-29.87 | last_loss=0.0034824793692678213\n",
      "main loop iter: 298\n",
      "time: 33036.290439100005\n",
      "COLLECT loop time: 109.78158229999826\n",
      "TRAIN loop time: 0.39499849999992875\n",
      "Iter 298 | replay=50000 | train_return_mean=-29.41 | last_loss=0.0029494324699044228\n",
      "main loop iter: 299\n",
      "time: 33146.4673262\n",
      "COLLECT loop time: 124.31382960000337\n",
      "TRAIN loop time: 0.39515250000113156\n",
      "Iter 299 | replay=50000 | train_return_mean=-80.81 | last_loss=0.0026476916391402483\n",
      "main loop iter: 300\n",
      "time: 33271.176620700004\n",
      "COLLECT loop time: 42.52948859999742\n",
      "TRAIN loop time: 0.3971103000003495\n",
      "EVAL time: 487.08355440000014\n",
      "[Eval it=300] R=1.72±131.53 succ=0.70 coll=0.00 max=0.30 len_suc=23.0 len_col=0.0 \n",
      "Iter 300 | replay=50000 | train_return_mean=18.27 | last_loss=0.0027279439382255077\n",
      "main loop iter: 301\n",
      "time: 33801.1872317\n",
      "COLLECT loop time: 65.64430040000298\n",
      "TRAIN loop time: 0.38683859999582637\n",
      "Iter 301 | replay=50000 | train_return_mean=41.68 | last_loss=0.0020103007555007935\n",
      "main loop iter: 302\n",
      "time: 33867.218704\n",
      "COLLECT loop time: 144.49823460000334\n",
      "TRAIN loop time: 0.36161519999586744\n",
      "Iter 302 | replay=50000 | train_return_mean=-61.52 | last_loss=0.0036820475943386555\n",
      "main loop iter: 303\n",
      "time: 34012.0787957\n",
      "COLLECT loop time: 153.5133610000048\n",
      "TRAIN loop time: 0.3970387000008486\n",
      "Iter 303 | replay=50000 | train_return_mean=-46.96 | last_loss=0.006366263143718243\n",
      "main loop iter: 304\n",
      "time: 34165.9894683\n",
      "COLLECT loop time: 139.97619880000275\n",
      "TRAIN loop time: 0.4100187999938498\n",
      "Iter 304 | replay=50000 | train_return_mean=-103.19 | last_loss=0.0056167226284742355\n",
      "main loop iter: 305\n",
      "time: 34306.3760243\n",
      "COLLECT loop time: 115.52624720000313\n",
      "TRAIN loop time: 0.4000510999976541\n",
      "Iter 305 | replay=50000 | train_return_mean=-53.93 | last_loss=0.02666233293712139\n",
      "main loop iter: 306\n",
      "time: 34422.3026419\n",
      "COLLECT loop time: 62.99977529999887\n",
      "TRAIN loop time: 0.3990216000020155\n",
      "Iter 306 | replay=50000 | train_return_mean=30.20 | last_loss=0.022176748141646385\n",
      "main loop iter: 307\n",
      "time: 34485.7017529\n",
      "COLLECT loop time: 71.45529879999958\n",
      "TRAIN loop time: 0.399293000002217\n",
      "Iter 307 | replay=50000 | train_return_mean=22.89 | last_loss=0.011814525350928307\n",
      "main loop iter: 308\n",
      "time: 34557.5566739\n",
      "COLLECT loop time: 44.120494800001325\n",
      "TRAIN loop time: 0.3886645000020508\n",
      "Iter 308 | replay=50000 | train_return_mean=37.31 | last_loss=0.008625570684671402\n",
      "main loop iter: 309\n",
      "time: 34602.0661217\n",
      "COLLECT loop time: 113.11870009999984\n",
      "TRAIN loop time: 0.4127338999969652\n",
      "Iter 309 | replay=50000 | train_return_mean=-25.50 | last_loss=0.016349203884601593\n",
      "main loop iter: 310\n",
      "time: 34715.5978281\n",
      "COLLECT loop time: 106.13814719999937\n",
      "TRAIN loop time: 0.4228981000051135\n",
      "Iter 310 | replay=50000 | train_return_mean=-51.48 | last_loss=0.009597918018698692\n",
      "main loop iter: 311\n",
      "time: 34822.1592255\n",
      "COLLECT loop time: 72.31335689999833\n",
      "TRAIN loop time: 0.3990862999999081\n",
      "Iter 311 | replay=50000 | train_return_mean=30.16 | last_loss=0.006860256195068359\n",
      "main loop iter: 312\n",
      "time: 34894.8719404\n",
      "COLLECT loop time: 84.2565573000029\n",
      "TRAIN loop time: 0.40823660000023665\n",
      "Iter 312 | replay=50000 | train_return_mean=9.75 | last_loss=0.011561281979084015\n",
      "main loop iter: 313\n",
      "time: 34979.5368731\n",
      "COLLECT loop time: 115.58114920000662\n",
      "TRAIN loop time: 0.47134819999337196\n",
      "Iter 313 | replay=50000 | train_return_mean=-52.04 | last_loss=0.009574363008141518\n",
      "main loop iter: 314\n",
      "time: 35095.5897686\n",
      "COLLECT loop time: 100.607843400001\n",
      "TRAIN loop time: 0.37954379999428056\n",
      "Iter 314 | replay=50000 | train_return_mean=-24.50 | last_loss=0.007973229512572289\n",
      "main loop iter: 315\n",
      "time: 35196.5773131\n",
      "COLLECT loop time: 77.56637239999691\n",
      "TRAIN loop time: 0.37708630000270205\n",
      "Iter 315 | replay=50000 | train_return_mean=23.27 | last_loss=0.006621278822422028\n",
      "main loop iter: 316\n",
      "time: 35274.521060600004\n",
      "COLLECT loop time: 119.10054669999954\n",
      "TRAIN loop time: 0.36569439999584574\n",
      "Iter 316 | replay=50000 | train_return_mean=-41.96 | last_loss=0.004724731668829918\n",
      "main loop iter: 317\n",
      "time: 35393.987540400005\n",
      "COLLECT loop time: 130.2395147999996\n",
      "TRAIN loop time: 0.372617299995909\n",
      "Iter 317 | replay=50000 | train_return_mean=-60.03 | last_loss=0.0037553012371063232\n",
      "main loop iter: 318\n",
      "time: 35524.5998028\n",
      "COLLECT loop time: 124.4297310999973\n",
      "TRAIN loop time: 0.36228100000153063\n",
      "Iter 318 | replay=50000 | train_return_mean=-39.29 | last_loss=0.004180735908448696\n",
      "main loop iter: 319\n",
      "time: 35649.3920566\n",
      "COLLECT loop time: 145.43661869999778\n",
      "TRAIN loop time: 0.3541098999994574\n",
      "Iter 319 | replay=50000 | train_return_mean=-74.06 | last_loss=0.003054274246096611\n",
      "main loop iter: 320\n",
      "time: 35795.1830677\n",
      "COLLECT loop time: 99.66107539999939\n",
      "TRAIN loop time: 0.3620297000015853\n",
      "Iter 320 | replay=50000 | train_return_mean=-47.22 | last_loss=0.0026687076315283775\n",
      "main loop iter: 321\n",
      "time: 35895.2064765\n",
      "COLLECT loop time: 28.436098300000594\n",
      "TRAIN loop time: 0.3761958999966737\n",
      "Iter 321 | replay=50000 | train_return_mean=63.71 | last_loss=0.00228613568469882\n",
      "main loop iter: 322\n",
      "time: 35924.019045400004\n",
      "COLLECT loop time: 100.95115639999858\n",
      "TRAIN loop time: 0.3740235000004759\n",
      "Iter 322 | replay=50000 | train_return_mean=-50.88 | last_loss=0.0018009175546467304\n",
      "main loop iter: 323\n",
      "time: 36025.344497800004\n",
      "COLLECT loop time: 90.97193770000013\n",
      "TRAIN loop time: 0.38732019999588374\n",
      "Iter 323 | replay=50000 | train_return_mean=0.09 | last_loss=0.0025417087599635124\n",
      "main loop iter: 324\n",
      "time: 36116.704055\n",
      "COLLECT loop time: 169.1826970999973\n",
      "TRAIN loop time: 0.3650045000031241\n",
      "Iter 324 | replay=50000 | train_return_mean=-134.89 | last_loss=0.004186287522315979\n",
      "main loop iter: 325\n",
      "time: 36286.252031100004\n",
      "COLLECT loop time: 89.42278979999537\n",
      "TRAIN loop time: 0.36525629999960074\n",
      "EVAL time: 521.9480162000036\n",
      "[Eval it=325] R=-19.93±140.95 succ=0.62 coll=0.00 max=0.38 len_suc=18.6 len_col=0.0 \n",
      "Iter 325 | replay=50000 | train_return_mean=-8.56 | last_loss=0.005965891294181347\n",
      "main loop iter: 326\n",
      "time: 36897.9889922\n",
      "COLLECT loop time: 104.3628400000016\n",
      "TRAIN loop time: 0.35720189999847207\n",
      "Iter 326 | replay=50000 | train_return_mean=-21.76 | last_loss=0.007744665257632732\n",
      "main loop iter: 327\n",
      "time: 37002.709183700004\n",
      "COLLECT loop time: 49.92804949999845\n",
      "TRAIN loop time: 0.3510152000017115\n",
      "Iter 327 | replay=50000 | train_return_mean=-12.24 | last_loss=0.00547189312055707\n",
      "main loop iter: 328\n",
      "time: 37052.9883864\n",
      "COLLECT loop time: 128.16642280000087\n",
      "TRAIN loop time: 0.36531880000256933\n",
      "Iter 328 | replay=50000 | train_return_mean=-57.78 | last_loss=0.009452413767576218\n",
      "main loop iter: 329\n",
      "time: 37181.5204679\n",
      "COLLECT loop time: 69.73748090000299\n",
      "TRAIN loop time: 0.3588166999979876\n",
      "Iter 329 | replay=50000 | train_return_mean=20.09 | last_loss=0.004869701340794563\n",
      "main loop iter: 330\n",
      "time: 37251.617036100004\n",
      "COLLECT loop time: 115.44161679999524\n",
      "TRAIN loop time: 0.38206860000354936\n",
      "Iter 330 | replay=50000 | train_return_mean=-42.85 | last_loss=0.0038024436216801405\n",
      "main loop iter: 331\n",
      "time: 37367.440977700004\n",
      "COLLECT loop time: 79.76978159999999\n",
      "TRAIN loop time: 0.39111539999430533\n",
      "Iter 331 | replay=50000 | train_return_mean=1.58 | last_loss=0.014591063372790813\n",
      "main loop iter: 332\n",
      "time: 37447.6020384\n",
      "COLLECT loop time: 65.03814470000361\n",
      "TRAIN loop time: 0.36765249999734806\n",
      "Iter 332 | replay=50000 | train_return_mean=-14.67 | last_loss=0.010395195335149765\n",
      "main loop iter: 333\n",
      "time: 37513.0080696\n",
      "COLLECT loop time: 153.13008500000433\n",
      "TRAIN loop time: 0.3806403999988106\n",
      "Iter 333 | replay=50000 | train_return_mean=-132.55 | last_loss=0.008388318121433258\n",
      "main loop iter: 334\n",
      "time: 37666.5190639\n",
      "COLLECT loop time: 134.71291570000176\n",
      "TRAIN loop time: 0.361796700002742\n",
      "Iter 334 | replay=50000 | train_return_mean=-91.85 | last_loss=0.0070557426661252975\n",
      "main loop iter: 335\n",
      "time: 37801.5940696\n",
      "COLLECT loop time: 110.57544129999587\n",
      "TRAIN loop time: 0.3697576000049594\n",
      "Iter 335 | replay=50000 | train_return_mean=-58.59 | last_loss=0.005965890362858772\n",
      "main loop iter: 336\n",
      "time: 37912.5395728\n",
      "COLLECT loop time: 105.6355990000011\n",
      "TRAIN loop time: 0.3669090999974287\n",
      "Iter 336 | replay=50000 | train_return_mean=-35.28 | last_loss=0.004756760783493519\n",
      "main loop iter: 337\n",
      "time: 38018.542360600004\n",
      "COLLECT loop time: 114.47318289999384\n",
      "TRAIN loop time: 0.3591000000014901\n",
      "Iter 337 | replay=50000 | train_return_mean=-84.74 | last_loss=0.005301268771290779\n",
      "main loop iter: 338\n",
      "time: 38133.3749008\n",
      "COLLECT loop time: 68.5066439000002\n",
      "TRAIN loop time: 0.37590430000273045\n",
      "Iter 338 | replay=50000 | train_return_mean=20.87 | last_loss=0.004109244793653488\n",
      "main loop iter: 339\n",
      "time: 38202.2577836\n",
      "COLLECT loop time: 157.74657730000035\n",
      "TRAIN loop time: 0.364892300000065\n",
      "Iter 339 | replay=50000 | train_return_mean=-134.72 | last_loss=0.004594743251800537\n",
      "main loop iter: 340\n",
      "time: 38360.3695413\n",
      "COLLECT loop time: 80.88867149999714\n",
      "TRAIN loop time: 0.36690420000377344\n",
      "Iter 340 | replay=50000 | train_return_mean=-1.47 | last_loss=0.003529802430421114\n",
      "main loop iter: 341\n",
      "time: 38441.625326\n",
      "COLLECT loop time: 99.84468599999673\n",
      "TRAIN loop time: 0.36256890000368003\n",
      "Iter 341 | replay=50000 | train_return_mean=-49.85 | last_loss=0.006574542261660099\n",
      "main loop iter: 342\n",
      "time: 38541.832738000005\n",
      "COLLECT loop time: 159.08980080000038\n",
      "TRAIN loop time: 0.3663673999981256\n",
      "Iter 342 | replay=50000 | train_return_mean=-126.60 | last_loss=0.006272302009165287\n",
      "main loop iter: 343\n",
      "time: 38701.2892382\n",
      "COLLECT loop time: 96.96080910000455\n",
      "TRAIN loop time: 0.4359545999977854\n",
      "Iter 343 | replay=50000 | train_return_mean=-0.51 | last_loss=0.005990455858409405\n",
      "main loop iter: 344\n",
      "time: 38798.6863113\n",
      "COLLECT loop time: 100.88326300000335\n",
      "TRAIN loop time: 0.3870212999972864\n",
      "Iter 344 | replay=50000 | train_return_mean=-49.70 | last_loss=0.005772116594016552\n",
      "main loop iter: 345\n",
      "time: 38899.956937300005\n",
      "COLLECT loop time: 136.0881839999929\n",
      "TRAIN loop time: 0.39402420000260463\n",
      "Iter 345 | replay=50000 | train_return_mean=-120.28 | last_loss=0.0041378336027264595\n",
      "main loop iter: 346\n",
      "time: 39036.439397300004\n",
      "COLLECT loop time: 115.65073109999503\n",
      "TRAIN loop time: 0.37330840000504395\n",
      "Iter 346 | replay=50000 | train_return_mean=-53.23 | last_loss=0.004163880832493305\n",
      "main loop iter: 347\n",
      "time: 39152.4637078\n",
      "COLLECT loop time: 96.61929529999907\n",
      "TRAIN loop time: 0.3851959000021452\n",
      "Iter 347 | replay=50000 | train_return_mean=-19.39 | last_loss=0.0032313810661435127\n",
      "main loop iter: 348\n",
      "time: 39249.468357800004\n",
      "COLLECT loop time: 72.87545390000014\n",
      "TRAIN loop time: 0.4175325999967754\n",
      "Iter 348 | replay=50000 | train_return_mean=-20.55 | last_loss=0.0035654534585773945\n",
      "main loop iter: 349\n",
      "time: 39322.761665\n",
      "COLLECT loop time: 117.22105270000611\n",
      "TRAIN loop time: 0.38274599999567727\n",
      "Iter 349 | replay=50000 | train_return_mean=-77.19 | last_loss=0.003329731058329344\n",
      "main loop iter: 350\n",
      "time: 39440.3658514\n",
      "COLLECT loop time: 64.23945590000221\n",
      "TRAIN loop time: 0.37656109999807086\n",
      "EVAL time: 694.7174031000031\n",
      "[Eval it=350] R=-48.68±142.16 succ=0.54 coll=0.00 max=0.46 len_suc=30.5 len_col=0.0 \n",
      "Iter 350 | replay=50000 | train_return_mean=29.25 | last_loss=0.002802459988743067\n",
      "main loop iter: 351\n",
      "time: 40199.6996538\n",
      "COLLECT loop time: 103.81989869999961\n",
      "TRAIN loop time: 0.3631985999963945\n",
      "Iter 351 | replay=50000 | train_return_mean=-39.72 | last_loss=0.0026285946369171143\n",
      "main loop iter: 352\n",
      "time: 40303.882912\n",
      "COLLECT loop time: 71.73793370000203\n",
      "TRAIN loop time: 0.4011129999998957\n",
      "Iter 352 | replay=50000 | train_return_mean=-20.66 | last_loss=0.002811326179653406\n",
      "main loop iter: 353\n",
      "time: 40376.0222975\n",
      "COLLECT loop time: 118.22597600000154\n",
      "TRAIN loop time: 0.42568620000383817\n",
      "Iter 353 | replay=50000 | train_return_mean=-90.72 | last_loss=0.0038334629498422146\n",
      "main loop iter: 354\n",
      "time: 40494.6743212\n",
      "COLLECT loop time: 167.17086080000445\n",
      "TRAIN loop time: 0.3843074999967939\n",
      "Iter 354 | replay=50000 | train_return_mean=-73.00 | last_loss=0.007168116047978401\n",
      "main loop iter: 355\n",
      "time: 40662.229652400005\n",
      "COLLECT loop time: 46.709454999996524\n",
      "TRAIN loop time: 0.392244100003154\n",
      "Iter 355 | replay=50000 | train_return_mean=14.37 | last_loss=0.0035286517813801765\n",
      "main loop iter: 356\n",
      "time: 40709.331624\n",
      "COLLECT loop time: 87.50765910000337\n",
      "TRAIN loop time: 0.36362129999906756\n",
      "Iter 356 | replay=50000 | train_return_mean=26.83 | last_loss=0.0019649139139801264\n",
      "main loop iter: 357\n",
      "time: 40797.203204000005\n",
      "COLLECT loop time: 59.707492299996375\n",
      "TRAIN loop time: 0.3739687999986927\n",
      "Iter 357 | replay=50000 | train_return_mean=-10.08 | last_loss=0.0015104080084711313\n",
      "main loop iter: 358\n",
      "time: 40857.2849299\n",
      "COLLECT loop time: 82.37522329999774\n",
      "TRAIN loop time: 0.4016842000055476\n",
      "Iter 358 | replay=50000 | train_return_mean=-40.70 | last_loss=0.0018866171594709158\n",
      "main loop iter: 359\n",
      "time: 40940.0621905\n",
      "COLLECT loop time: 151.86666179999884\n",
      "TRAIN loop time: 0.3693487000055029\n",
      "Iter 359 | replay=50000 | train_return_mean=-85.38 | last_loss=0.0027210358530282974\n",
      "main loop iter: 360\n",
      "time: 41092.298358\n",
      "COLLECT loop time: 121.90897720000066\n",
      "TRAIN loop time: 0.3876187999994727\n",
      "Iter 360 | replay=50000 | train_return_mean=-43.90 | last_loss=0.0021444829180836678\n",
      "main loop iter: 361\n",
      "time: 41214.5952189\n",
      "COLLECT loop time: 122.18523299999651\n",
      "TRAIN loop time: 0.39549750000151107\n",
      "Iter 361 | replay=50000 | train_return_mean=-33.92 | last_loss=0.0029412098228931427\n",
      "main loop iter: 362\n",
      "time: 41337.1762909\n",
      "COLLECT loop time: 68.1895549999972\n",
      "TRAIN loop time: 0.376129199998104\n",
      "Iter 362 | replay=50000 | train_return_mean=23.73 | last_loss=0.0042958310805261135\n",
      "main loop iter: 363\n",
      "time: 41405.7421257\n",
      "COLLECT loop time: 136.75454850000096\n",
      "TRAIN loop time: 0.3870609000005061\n",
      "Iter 363 | replay=50000 | train_return_mean=-60.19 | last_loss=0.0057473620399832726\n",
      "main loop iter: 364\n",
      "time: 41542.884054300004\n",
      "COLLECT loop time: 131.86362199999712\n",
      "TRAIN loop time: 0.37766109999938635\n",
      "Iter 364 | replay=50000 | train_return_mean=-106.85 | last_loss=0.015570947900414467\n",
      "main loop iter: 365\n",
      "time: 41675.125610200004\n",
      "COLLECT loop time: 98.72343109999929\n",
      "TRAIN loop time: 0.38337329999922076\n",
      "Iter 365 | replay=50000 | train_return_mean=-23.63 | last_loss=0.009440584108233452\n",
      "main loop iter: 366\n",
      "time: 41774.2327284\n",
      "COLLECT loop time: 62.74578330000077\n",
      "TRAIN loop time: 0.381952600000659\n",
      "Iter 366 | replay=50000 | train_return_mean=27.19 | last_loss=0.0056406306102871895\n",
      "main loop iter: 367\n",
      "time: 41837.3606361\n",
      "COLLECT loop time: 97.58092659999966\n",
      "TRAIN loop time: 0.4255879000047571\n",
      "Iter 367 | replay=50000 | train_return_mean=-28.14 | last_loss=0.00418108468875289\n",
      "main loop iter: 368\n",
      "time: 41935.367457500004\n",
      "COLLECT loop time: 156.9222465999992\n",
      "TRAIN loop time: 0.3584435000011581\n",
      "Iter 368 | replay=50000 | train_return_mean=-106.94 | last_loss=0.003121504792943597\n",
      "main loop iter: 369\n",
      "time: 42092.6483003\n",
      "COLLECT loop time: 135.4674507000018\n",
      "TRAIN loop time: 0.36243849999300437\n",
      "Iter 369 | replay=50000 | train_return_mean=-83.85 | last_loss=0.002358501311391592\n",
      "main loop iter: 370\n",
      "time: 42228.4783406\n",
      "COLLECT loop time: 92.70927720000327\n",
      "TRAIN loop time: 0.358706599996367\n",
      "Iter 370 | replay=50000 | train_return_mean=-25.88 | last_loss=0.001869327388703823\n",
      "main loop iter: 371\n",
      "time: 42321.5464663\n",
      "COLLECT loop time: 102.8575473000019\n",
      "TRAIN loop time: 0.4214861000000383\n",
      "Iter 371 | replay=50000 | train_return_mean=-62.92 | last_loss=0.0028318651020526886\n",
      "main loop iter: 372\n",
      "time: 42424.8258508\n",
      "COLLECT loop time: 109.28676390000328\n",
      "TRAIN loop time: 0.3760534999964875\n",
      "Iter 372 | replay=50000 | train_return_mean=-72.68 | last_loss=0.002247688127681613\n",
      "main loop iter: 373\n",
      "time: 42534.4888004\n",
      "COLLECT loop time: 79.6250258\n",
      "TRAIN loop time: 0.3584389000025112\n",
      "Iter 373 | replay=50000 | train_return_mean=-20.33 | last_loss=0.003283234080299735\n",
      "main loop iter: 374\n",
      "time: 42614.4724837\n",
      "COLLECT loop time: 172.78082509999513\n",
      "TRAIN loop time: 0.38645910000195727\n",
      "Iter 374 | replay=50000 | train_return_mean=-142.91 | last_loss=0.0032186568714678288\n",
      "main loop iter: 375\n",
      "time: 42787.6401023\n",
      "COLLECT loop time: 163.61572130000422\n",
      "TRAIN loop time: 0.4613134999963222\n",
      "EVAL time: 800.3669399999999\n",
      "[Eval it=375] R=-77.14±143.69 succ=0.42 coll=0.00 max=0.58 len_suc=17.2 len_col=0.0 \n",
      "Iter 375 | replay=50000 | train_return_mean=-116.72 | last_loss=0.0019768686033785343\n",
      "main loop iter: 376\n",
      "time: 43752.0845026\n",
      "COLLECT loop time: 113.91211289999774\n",
      "TRAIN loop time: 0.4010063000023365\n",
      "Iter 376 | replay=50000 | train_return_mean=-61.58 | last_loss=0.009471340104937553\n",
      "main loop iter: 377\n",
      "time: 43866.3979602\n",
      "COLLECT loop time: 84.19657249999727\n",
      "TRAIN loop time: 0.40945140000258107\n",
      "Iter 377 | replay=50000 | train_return_mean=-40.20 | last_loss=0.008715331554412842\n",
      "main loop iter: 378\n",
      "time: 43951.0042863\n",
      "COLLECT loop time: 132.0480555000031\n",
      "TRAIN loop time: 0.679433400000562\n",
      "Iter 378 | replay=50000 | train_return_mean=-135.31 | last_loss=0.01696520298719406\n",
      "main loop iter: 379\n",
      "time: 44083.7319672\n",
      "COLLECT loop time: 138.75806759999978\n",
      "TRAIN loop time: 0.3830404000036651\n",
      "Iter 379 | replay=50000 | train_return_mean=-68.17 | last_loss=0.024874800816178322\n",
      "main loop iter: 380\n",
      "time: 44222.873214700005\n",
      "COLLECT loop time: 114.36564839999483\n",
      "TRAIN loop time: 0.44168419999914477\n",
      "Iter 380 | replay=50000 | train_return_mean=-66.83 | last_loss=0.01810600236058235\n",
      "main loop iter: 381\n",
      "time: 44337.6810821\n",
      "COLLECT loop time: 139.18723379999574\n",
      "TRAIN loop time: 0.4118333000005805\n",
      "Iter 381 | replay=50000 | train_return_mean=-83.13 | last_loss=0.013122674077749252\n",
      "main loop iter: 382\n",
      "time: 44477.2804408\n",
      "COLLECT loop time: 145.18112200000178\n",
      "TRAIN loop time: 0.3850296000018716\n",
      "Iter 382 | replay=50000 | train_return_mean=-64.63 | last_loss=0.011611818335950375\n",
      "main loop iter: 383\n",
      "time: 44622.8468461\n",
      "COLLECT loop time: 98.5411408\n",
      "TRAIN loop time: 0.3996114999972633\n",
      "Iter 383 | replay=50000 | train_return_mean=-24.51 | last_loss=0.012258486822247505\n",
      "main loop iter: 384\n",
      "time: 44721.7878836\n",
      "COLLECT loop time: 102.65090870000131\n",
      "TRAIN loop time: 0.3709216999995988\n",
      "Iter 384 | replay=50000 | train_return_mean=-40.71 | last_loss=0.011031344532966614\n",
      "main loop iter: 385\n",
      "time: 44824.8099759\n",
      "COLLECT loop time: 136.04537129999517\n",
      "TRAIN loop time: 0.40958410000166623\n",
      "Iter 385 | replay=50000 | train_return_mean=-86.07 | last_loss=0.009801367297768593\n",
      "main loop iter: 386\n",
      "time: 44961.2652027\n",
      "COLLECT loop time: 125.80611219999992\n",
      "TRAIN loop time: 0.484500400001707\n",
      "Iter 386 | replay=50000 | train_return_mean=-59.16 | last_loss=0.009035046212375164\n",
      "main loop iter: 387\n",
      "time: 45087.5561006\n",
      "COLLECT loop time: 104.23632910000015\n",
      "TRAIN loop time: 0.45575320000352804\n",
      "Iter 387 | replay=50000 | train_return_mean=-2.26 | last_loss=0.008169898763298988\n",
      "main loop iter: 388\n",
      "time: 45192.2484634\n",
      "COLLECT loop time: 152.37940180000442\n",
      "TRAIN loop time: 0.4074592999968445\n",
      "Iter 388 | replay=50000 | train_return_mean=-133.11 | last_loss=0.007672517094761133\n",
      "main loop iter: 389\n",
      "time: 45345.0355912\n",
      "COLLECT loop time: 112.1135534999994\n",
      "TRAIN loop time: 0.4460719999988214\n",
      "Iter 389 | replay=50000 | train_return_mean=-31.15 | last_loss=0.006910932715982199\n",
      "main loop iter: 390\n",
      "time: 45457.5955634\n",
      "COLLECT loop time: 129.7929107000018\n",
      "TRAIN loop time: 0.44608729999890784\n",
      "Iter 390 | replay=50000 | train_return_mean=-90.63 | last_loss=0.006520105991512537\n",
      "main loop iter: 391\n",
      "time: 45587.834879300004\n",
      "COLLECT loop time: 55.55749139999534\n",
      "TRAIN loop time: 0.3864547000048333\n",
      "Iter 391 | replay=50000 | train_return_mean=6.16 | last_loss=0.0064825862646102905\n",
      "main loop iter: 392\n",
      "time: 45643.7790998\n",
      "COLLECT loop time: 98.17660530000285\n",
      "TRAIN loop time: 0.4470712000038475\n",
      "Iter 392 | replay=50000 | train_return_mean=-59.92 | last_loss=0.00702808890491724\n",
      "main loop iter: 393\n",
      "time: 45742.403097200004\n",
      "COLLECT loop time: 148.12853539999924\n",
      "TRAIN loop time: 0.45614029999705963\n",
      "Iter 393 | replay=50000 | train_return_mean=-110.66 | last_loss=0.009440861642360687\n",
      "main loop iter: 394\n",
      "time: 45890.988129800004\n",
      "COLLECT loop time: 139.0268145999944\n",
      "TRAIN loop time: 0.47450030000618426\n",
      "Iter 394 | replay=50000 | train_return_mean=-55.11 | last_loss=0.00823402963578701\n",
      "main loop iter: 395\n",
      "time: 46030.489785800004\n",
      "COLLECT loop time: 60.280100399999355\n",
      "TRAIN loop time: 0.4385167000000365\n",
      "Iter 395 | replay=50000 | train_return_mean=30.30 | last_loss=0.007277755998075008\n",
      "main loop iter: 396\n",
      "time: 46091.2086692\n",
      "COLLECT loop time: 86.63556570000219\n",
      "TRAIN loop time: 0.4505702999958885\n",
      "Iter 396 | replay=50000 | train_return_mean=-0.91 | last_loss=0.008325321599841118\n",
      "main loop iter: 397\n",
      "time: 46178.2951215\n",
      "COLLECT loop time: 112.53210150000086\n",
      "TRAIN loop time: 0.4477522000015597\n",
      "Iter 397 | replay=50000 | train_return_mean=-56.89 | last_loss=0.008748558349907398\n",
      "main loop iter: 398\n",
      "time: 46291.2752706\n",
      "COLLECT loop time: 133.5720674999975\n",
      "TRAIN loop time: 0.37666600000375183\n",
      "Iter 398 | replay=50000 | train_return_mean=-95.38 | last_loss=0.00809408724308014\n",
      "main loop iter: 399\n",
      "time: 46425.2242992\n",
      "COLLECT loop time: 19.092311299995345\n",
      "TRAIN loop time: 0.4861921000047005\n",
      "Iter 399 | replay=50000 | train_return_mean=90.28 | last_loss=0.006757472176104784\n",
      "main loop iter: 400\n",
      "time: 46444.8030801\n",
      "COLLECT loop time: 144.41492429999926\n",
      "TRAIN loop time: 0.4188540000031935\n",
      "EVAL time: 621.3918315999981\n",
      "[Eval it=400] R=-29.72±139.49 succ=0.60 coll=0.00 max=0.40 len_suc=27.0 len_col=0.0 \n",
      "Iter 400 | replay=50000 | train_return_mean=-105.46 | last_loss=0.00781347043812275\n",
      "main loop iter: 401\n",
      "time: 47211.0289274\n",
      "COLLECT loop time: 85.49943409999833\n",
      "TRAIN loop time: 0.3733868999988772\n",
      "Iter 401 | replay=50000 | train_return_mean=-17.92 | last_loss=0.007430432364344597\n",
      "main loop iter: 402\n",
      "time: 47296.902026\n",
      "COLLECT loop time: 81.6518270000015\n",
      "TRAIN loop time: 0.38165399999707006\n",
      "Iter 402 | replay=50000 | train_return_mean=2.24 | last_loss=0.006901550572365522\n",
      "main loop iter: 403\n",
      "time: 47378.935864700004\n",
      "COLLECT loop time: 66.60042539999995\n",
      "TRAIN loop time: 0.42145679999521235\n",
      "Iter 403 | replay=50000 | train_return_mean=26.14 | last_loss=0.006306815426796675\n",
      "main loop iter: 404\n",
      "time: 47445.9580472\n",
      "COLLECT loop time: 61.76051919999736\n",
      "TRAIN loop time: 0.3842704000053345\n",
      "Iter 404 | replay=50000 | train_return_mean=9.83 | last_loss=0.0069916872307658195\n",
      "main loop iter: 405\n",
      "time: 47508.1029912\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_iters = 500\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(\"START\")\n",
    "\n",
    "episodes_collected = 0\n",
    "episodes_to_collect = 100\n",
    "\n",
    "episode_success = np.zeros(episodes_to_collect, dtype = bool)\n",
    "episode_collision = np.zeros(episodes_to_collect, dtype = bool)\n",
    "episode_max_step = np.zeros(episodes_to_collect)\n",
    "episode_reward = np.full((episodes_to_collect, cfg.max_episode_steps),np.nan,dtype=float)\n",
    "episode_z_mc = np.full((episodes_to_collect, cfg.max_episode_steps),np.nan,dtype=float)\n",
    "episode_z_mcts = np.full((episodes_to_collect, cfg.max_episode_steps),np.nan,dtype=float)\n",
    "\n",
    "for it in range(num_iters):\n",
    "    now = time.perf_counter()\n",
    "    print(f\"main loop iter: {it}\")\n",
    "    print(f\"time: {now-start_time}\")\n",
    "    last_time = now\n",
    "    \n",
    "    planner.set_training_iter(it)\n",
    "\n",
    "    # ---- Collect ----\n",
    "    ep_returns = []\n",
    "    for _ in range(cfg.collect_episodes_per_iter):\n",
    "        stats, episode = collect_one_episode_hybrid(\n",
    "            env_real=env_real,\n",
    "            planner=planner,\n",
    "            replay_buffer=replay,\n",
    "            max_steps=cfg.max_episode_steps,\n",
    "            gamma=cfg.gamma_mc,\n",
    "            training=True,\n",
    "        )\n",
    "        if episodes_collected < episodes_to_collect:\n",
    "            episode_success[episodes_collected] = stats[\"success\"]\n",
    "            episode_collision[episodes_collected] = stats[\"collision\"]\n",
    "            episode_max_step[episodes_collected] = stats[\"max_steps_reached\"]\n",
    "            for i, step in enumerate(episode):\n",
    "                episode_reward[episodes_collected, i] = step[\"reward\"]\n",
    "                episode_z_mc[episodes_collected, i] = step[\"z_mc\"]\n",
    "                episode_z_mcts[episodes_collected, i] = step[\"z_mcts\"]\n",
    "        episodes_collected += 1\n",
    "\n",
    "        ep_returns.append(stats[\"return\"])\n",
    "        logs[\"ep_return\"].append(stats[\"return\"])\n",
    "        logs[\"ep_length\"].append(stats[\"length\"])\n",
    "        \n",
    "    now = time.perf_counter()\n",
    "    print(\"COLLECT loop time:\", now - last_time)\n",
    "    last_time = now\n",
    "\n",
    "    # ---- Train (baseline MLE/value regression) ----\n",
    "    if len(replay) >= cfg.batch_size:\n",
    "        for _ in range(cfg.train_steps_per_iter):\n",
    "            batch = replay.sample(cfg.batch_size, device=device, rng=np.random.default_rng(SEED))\n",
    "            \n",
    "            loss_dict = train_step_mle(\n",
    "                net=net,\n",
    "                optimizer=optimizer,\n",
    "                batch=batch,\n",
    "                w_value=cfg.value_loss_weight,\n",
    "                w_policy=cfg.policy_loss_weight,\n",
    "                grad_clip_norm=1.0,\n",
    "            )\n",
    "            \n",
    "            for k, v in loss_dict.items():\n",
    "                logs[k].append(v)\n",
    "                \n",
    "        now = time.perf_counter()\n",
    "        print(\"TRAIN loop time:\", now - last_time)\n",
    "        last_time = now\n",
    "\n",
    "    # ---- Eval (fixed seeds) ----\n",
    "    if it != 0 and (it % cfg.eval_every) == 0:\n",
    "        eval_stats, traces = run_eval_episodes(\n",
    "            env_eval=env_eval,\n",
    "            planner=planner,\n",
    "            seeds=EVAL_SEEDS,\n",
    "            max_steps=cfg.max_episode_steps,\n",
    "            goal_reward=env_eval._goal_reward,\n",
    "            collision_reward=env_eval._collision_reward,\n",
    "        )\n",
    "\n",
    "        for seed, tr in traces.items():\n",
    "            tr[\"training_iteration\"] = it\n",
    "\n",
    "        path = os.path.join(EVAL_DIR, f\"traces_ep{it:06d}.pkl\")\n",
    "    \n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(traces, f)\n",
    "\n",
    "        \n",
    "        logs[\"iter_idx_eval\"].append(it)\n",
    "        logs[\"eval_return_mean\"].append(eval_stats[\"eval_return_mean\"])\n",
    "        logs[\"eval_return_std\"].append(eval_stats[\"eval_return_std\"])\n",
    "        logs[\"eval_length_mean\"].append(eval_stats[\"eval_length_mean\"])\n",
    "        logs[\"success_rate\"].append(eval_stats[\"success_rate\"])\n",
    "        logs[\"collision_rate\"].append(eval_stats[\"collision_rate\"])\n",
    "        logs[\"eval_length_succes\"].append(eval_stats[\"eval_length_mean_successes\"])\n",
    "        logs[\"eval_length_collision\"].append(eval_stats[\"eval_length_mean_collisions\"])\n",
    "        logs[\"max_step_rate\"].append(eval_stats[\"max_step_rate\"])\n",
    "\n",
    "        now = time.perf_counter()\n",
    "        print(\"EVAL time:\", now - last_time)\n",
    "        last_time = now\n",
    "        \n",
    "        print(\n",
    "            f\"[Eval it={it}] \"\n",
    "            f\"R={eval_stats['eval_return_mean']:.2f}±{eval_stats['eval_return_std']:.2f} \"\n",
    "            f\"succ={eval_stats['success_rate']:.2f} \"\n",
    "            f\"coll={eval_stats['collision_rate']:.2f} \"\n",
    "            f\"max={eval_stats['max_step_rate']:.2f} \"\n",
    "            f\"len_suc={eval_stats['eval_length_mean_successes']:.1f} \"\n",
    "            f\"len_col={eval_stats['eval_length_mean_collisions']:.1f} \"\n",
    "        )\n",
    "\n",
    "    last_loss = logs[\"loss_total\"][-1] if logs[\"loss_total\"] else None\n",
    "    print(\n",
    "        f\"Iter {it} | replay={len(replay)} | \"\n",
    "        f\"train_return_mean={np.mean(ep_returns):.2f} | last_loss={last_loss}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25384aa5-180a-40d2-8053-dab4ac68f91a",
   "metadata": {},
   "source": [
    "# Debug Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844c984a564d00c",
   "metadata": {},
   "source": [
    "## Plot for length episode and discount factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d303ae3d7a670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T12:52:00.347509Z",
     "start_time": "2026-01-23T12:51:59.955742Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(sum(episode_max_step))\n",
    "plot_episodes = np.logical_or(episode_success, np.logical_or(episode_max_step, episode_collision))\n",
    "#plot_episodes = np.logical_or(episode_success,episode_collision)\n",
    "#plot_episodes = episode_success\n",
    "#plot_episodes = episode_collision\n",
    "#plot_episodes= episode_max_step\n",
    "\n",
    "plot_value = episode_z_mc\n",
    "\n",
    "plt.figure()\n",
    "for ep in np.where(plot_episodes)[0]:\n",
    "    plt.plot(plot_value[ep], alpha=0.3)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Reward\")\n",
    "#plt.ylim(-2,1)\n",
    "#plt.xlim(0,40)\n",
    "plt.title(\"Reward Trajectories (Successful Episodes)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd07941-56e3-4c05-bf1f-c75c6a373b63",
   "metadata": {},
   "source": [
    "# Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a05d54-32c2-4e43-8c9a-4c81457032d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avg(x, w=20):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if len(x) < w:\n",
    "        return x\n",
    "    return np.convolve(x, np.ones(w)/w, mode=\"valid\")\n",
    "\n",
    "# Train return moving average\n",
    "plt.figure()\n",
    "plt.plot(logs[\"ep_return\"])\n",
    "plt.title(\"Train episode return\")\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.ylabel(\"return\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(moving_avg(logs[\"ep_return\"], w=20))\n",
    "plt.title(\"Train episode return (moving avg)\")\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.ylabel(\"return\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Eval return mean\n",
    "if logs[\"eval_return_mean\"]:\n",
    "    #print(logs[\"eval_return_mean\"])\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"iter_idx_eval\"], logs[\"eval_return_mean\"], marker=\"o\")\n",
    "    plt.title(\"Eval return mean (fixed seeds)\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"return\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Eval success rate\n",
    "if logs[\"success_rate\"]:\n",
    "    #print(logs[\"success_rate\"])\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"iter_idx_eval\"], logs[\"success_rate\"], marker=\"o\", label=\"Success rate\")\n",
    "    plt.plot(logs[\"iter_idx_eval\"], logs[\"collision_rate\"], marker=\"o\", label=\"Collision rate\")\n",
    "    plt.plot(logs[\"iter_idx_eval\"], logs[\"max_step_rate\"], marker=\"o\", label=\"Max step rate\")\n",
    "    plt.title(\"Eval success rate (fixed seeds)\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"success rate\")\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if logs[\"eval_length_succes\"]:\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"iter_idx_eval\"], logs[\"eval_length_succes\"], marker=\"o\", label = \"Length succesfull episode\")\n",
    "    plt.plot(logs[\"iter_idx_eval\"], logs[\"eval_length_collision\"], marker=\"o\", label = \"Length collision episode\")\n",
    "    plt.title(\"Eval length episode (fixed seeds)\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"Length epispde\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Losses\n",
    "if logs[\"loss_total\"]:\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"loss_total\"])\n",
    "    plt.title(\"Total loss\")\n",
    "    plt.xlabel(\"train steps\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"loss_value\"])\n",
    "    plt.title(\"Value loss\")\n",
    "    plt.xlabel(\"train steps\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"loss_policy\"])\n",
    "    plt.title(\"Policy loss (mu/log_std regression)\")\n",
    "    plt.xlabel(\"train steps\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(logs[\"loss_policy_distill\"])\n",
    "    plt.title(\"Policy loss (imitation loss)\")\n",
    "    plt.xlabel(\"train steps\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a6e19-55a7-4122-9b57-51c9f7d42787",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13e20f-5ee5-48a2-a31f-018f4d15eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "num_iters = 30  # start with 30; increase later\n",
    "\n",
    "# Add eval logs\n",
    "logs.setdefault(\"eval_return_mean\", [])\n",
    "logs.setdefault(\"eval_return_std\", [])\n",
    "logs.setdefault(\"eval_length_mean\", [])\n",
    "logs.setdefault(\"success_rate\", [])\n",
    "logs.setdefault(\"collision_rate\", [])\n",
    "logs.setdefault(\"iter_idx_eval\", [])\n",
    "\n",
    "# Simple schedules: start clean\n",
    "def lambda_gauss(iter_idx: int) -> float:\n",
    "    return 0.0  # baseline: off\n",
    "\n",
    "def value_mix(iter_idx: int):\n",
    "    return 1.0, 0.0  # baseline: use z_mcts only\n",
    "\n",
    "\n",
    "for it in range(num_iters):\n",
    "    # tell planner what outer iteration we are in\n",
    "    planner.set_training_iter(it)\n",
    "\n",
    "    # --- Collect episodes ---\n",
    "    ep_returns = []\n",
    "    ep_lengths = []\n",
    "    for _ in range(cfg.collect_episodes_per_iter):\n",
    "        stats, _ = collect_one_episode_hybrid(\n",
    "            env_real=env_real,\n",
    "            planner=planner,\n",
    "            replay_buffer=replay,\n",
    "            max_steps=cfg.max_episode_steps,\n",
    "            gamma=cfg.gamma,\n",
    "            training=True,\n",
    "        )\n",
    "        ep_returns.append(stats[\"return\"])\n",
    "        ep_lengths.append(stats[\"length\"])\n",
    "        logs[\"ep_return\"].append(stats[\"return\"])\n",
    "        logs[\"ep_length\"].append(stats[\"length\"])\n",
    "\n",
    "    # --- Train ---\n",
    "    if len(replay) >= cfg.batch_size:\n",
    "        w_mcts, w_mc = value_mix(it)\n",
    "        w_gauss = lambda_gauss(it)\n",
    "\n",
    "        for _ in range(cfg.train_steps_per_iter):\n",
    "            batch = replay.sample(cfg.batch_size, device=device, rng=np.random.default_rng(SEED))\n",
    "            loss_dict = train_step_hybrid(\n",
    "                net=net,\n",
    "                optimizer=optimizer,\n",
    "                batch=batch,\n",
    "                w_value_mcts=w_mcts * cfg.value_loss_weight,\n",
    "                w_value_mc=w_mc * cfg.value_loss_weight,\n",
    "                w_policy_imitation=cfg.policy_loss_weight,\n",
    "                w_gaussian_reg=w_gauss * cfg.policy_loss_weight,\n",
    "                grad_clip_norm=1.0,\n",
    "            )\n",
    "            for k, v in loss_dict.items():\n",
    "                logs[k].append(v)\n",
    "\n",
    "    # --- Eval (fixed seeds) ---\n",
    "    if (it % cfg.eval_every) == 0:\n",
    "        eval_stats = run_eval_episodes(\n",
    "            env_eval=env_eval,\n",
    "            planner=planner,\n",
    "            seeds=EVAL_SEEDS,\n",
    "            max_steps=cfg.max_episode_steps,\n",
    "            goal_reward=env_eval._goal_reward,\n",
    "            collision_reward=env_eval._collision_reward,\n",
    "        )\n",
    "        logs[\"iter_idx_eval\"].append(it)\n",
    "        logs[\"eval_return_mean\"].append(eval_stats[\"eval_return_mean\"])\n",
    "        logs[\"eval_return_std\"].append(eval_stats[\"eval_return_std\"])\n",
    "        logs[\"eval_length_mean\"].append(eval_stats[\"eval_length_mean\"])\n",
    "        logs[\"success_rate\"].append(eval_stats[\"success_rate\"])\n",
    "        logs[\"collision_rate\"].append(eval_stats[\"collision_rate\"])\n",
    "\n",
    "        print(\n",
    "            f\"[Eval it={it}] \"\n",
    "            f\"R={eval_stats['eval_return_mean']:.2f}±{eval_stats['eval_return_std']:.2f} \"\n",
    "            f\"len={eval_stats['eval_length_mean']:.1f} \"\n",
    "            f\"succ={eval_stats['success_rate']:.2f} \"\n",
    "            f\"coll={eval_stats['collision_rate']:.2f}\"\n",
    "        )\n",
    "\n",
    "    last_loss = logs[\"loss_total\"][-1] if logs[\"loss_total\"] else None\n",
    "    print(\n",
    "        f\"Iter {it} | replay={len(replay)} | \"\n",
    "        f\"train_return_mean={np.mean(ep_returns):.2f} | \"\n",
    "        f\"last_loss={last_loss}\"\n",
    "    )\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
